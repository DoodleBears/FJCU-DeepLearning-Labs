{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneline_log(text):\n",
    "    sys.stdout.write('\\r')\n",
    "    sys.stdout.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression():\n",
    "    def __init__(self):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "\n",
    "    def linear(self, x, w, b):\n",
    "\n",
    "        return w * x.T + b\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "\n",
    "        x = np.clip(x, -709.78, 709.78)\n",
    "\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def forward(self, x, w, b):\n",
    "        x = np.mat(x)\n",
    "        w = np.mat(w)\n",
    "        # print(f'x shape: {np.shape(x)}')\n",
    "        # print(f'w shape: {np.shape(w)}')\n",
    "        net_input = self.linear(x, w, b)\n",
    "        # print(f'net_input: {net_input}')\n",
    "        y_estimate = self.sigmoid(net_input)\n",
    "\n",
    "        return y_estimate\n",
    "\n",
    "\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CrossEntropy\n",
    "class BinaryCrossEntropy():\n",
    "    def __init__(self):\n",
    "        super(BinaryCrossEntropy, self).__init__()\n",
    "    \n",
    "    def cross_entropy(self, y_pred, target):\n",
    "        x = target*np.log(y_pred) + (1-target)*np.log(1-y_pred)\n",
    "\n",
    "        return -(np.mean(x))\n",
    "\n",
    "    def forward(self, y_pred, target):\n",
    "\n",
    "        return self.cross_entropy(y_pred, target)\n",
    "criterion = BinaryCrossEntropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Function: Cross-entropy loss\n",
    "# used to calculate the loss of estimate\n",
    "# a: estimate value of y\n",
    "# y: true value of y\n",
    "def calculate_cross_entropy(y, a):\n",
    "    return -np.nan_to_num(np.multiply(y, np.log(a)) + np.multiply((1-y), np.log(1-a))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate random weight for each layer\n",
    "# number of weight = input * neuron of next layer\n",
    "\n",
    "# return value is 2D array of weight w_ji \n",
    "# w_ji means for the j neuron, the weight of input i\n",
    "random_scalar = 100\n",
    "def generate_layer_weight(seed, neuron, input):\n",
    "    np.random.seed(seed) # set seed for weight random\n",
    "    # w_ji 其中 j 对应 neuron, i 对应 input，所以 reshape 也同样按照如此进行\n",
    "    weight = np.random.randn(neuron,input) / random_scalar\n",
    "    # weight = np.zeros((neuron,input))\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate random bias for each layer\n",
    "# number of bias = neuron of layer\n",
    "\n",
    "# return value is vector of bias\n",
    "def generate_layer_bias(seed, neuron):\n",
    "    np.random.seed(seed) # set seed for bias random\n",
    "    bias = np.random.randn(neuron, 1) / random_scalar\n",
    "    # bias = np.zeros((neuron,1))\n",
    "    return bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(value):\n",
    "    if value == 9:\n",
    "        return np.array([0,0,0,1])\n",
    "    elif value == 8:\n",
    "        return np.array([0,0,1,0])\n",
    "    elif value == 3:\n",
    "        return np.array([0,1,0,0])\n",
    "    elif value == 0:\n",
    "        return np.array([1,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('================== Start ==================')\n",
    "pd_train_origin = pd.read_csv('data/lab3_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保留 label 为 0、3、8、9 的 data\n",
    "# 用 drop() 的方法，参见: https://www.cnblogs.com/everfight/p/pandas_condition_remove.html\n",
    "pd_train_origin = pd_train_origin[(pd_train_origin.label == 0) \n",
    "                                | (pd_train_origin.label == 3) \n",
    "                                | (pd_train_origin.label == 8) \n",
    "                                | (pd_train_origin.label == 9) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_train = pd_train_origin.sample(frac=0.8, random_state=2)\n",
    "pd_validate = pd_train_origin.drop(index=pd_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3200 entries, 1 to 15994\n",
      "Columns: 785 entries, label to pixel784\n",
      "dtypes: int64(785)\n",
      "memory usage: 19.2 MB\n"
     ]
    }
   ],
   "source": [
    "pd_validate.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12800 entries, 464 to 13599\n",
      "Columns: 785 entries, label to pixel784\n",
      "dtypes: int64(785)\n",
      "memory usage: 76.8 MB\n"
     ]
    }
   ],
   "source": [
    "pd_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = pd_train.drop(['label'], axis=1)\n",
    "train_feature = train_feature / 255\n",
    "train_target = pd.DataFrame(pd_train.label)\n",
    "train_feature = np.array(train_feature)\n",
    "train_target = np.array(train_target)\n",
    "\n",
    "validate_feature = pd_validate.drop(['label'], axis=1)\n",
    "validate_feature = validate_feature / 255\n",
    "validate_target = pd.DataFrame(pd_validate.label)\n",
    "validate_feature = np.array(validate_feature)\n",
    "validate_target = np.array(validate_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一共 len(train_feature) 笔 data\n",
    "# 每一笔 data 有 784 个 pixel\n",
    "\n",
    "w = {} # weight of layers\n",
    "b = {} # bias of layers\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 0, weight shape: (12, 784)\n",
      "[[-0.00416758 -0.00056267 -0.02136196 ... -0.00616844  0.00321336\n",
      "  -0.00946447]\n",
      " [-0.00530139 -0.01259207  0.01677544 ... -0.00328425 -0.00562311\n",
      "   0.00117914]\n",
      " [ 0.00738638 -0.01587296  0.001532   ... -0.00842856  0.01004047\n",
      "   0.00054583]\n",
      " ...\n",
      " [-0.00545023 -0.00350528  0.01290577 ...  0.00489264  0.02207854\n",
      "  -0.00779413]\n",
      " [ 0.00637325  0.00928663  0.00553019 ...  0.00933935 -0.01459427\n",
      "   0.00129041]\n",
      " [ 0.00933665  0.00643812 -0.00766691 ...  0.01172525  0.00610519\n",
      "  -0.0129887 ]]\n",
      "layer 0, bias shape: (12, 1)\n",
      "layer 1, weight shape: (4, 12)\n",
      "[[-4.16757847e-03 -5.62668272e-04 -2.13619610e-02  1.64027081e-02\n",
      "  -1.79343559e-02 -8.41747366e-03  5.02881417e-03 -1.24528809e-02\n",
      "  -1.05795222e-02 -9.09007615e-03  5.51454045e-03  2.29220801e-02]\n",
      " [ 4.15393930e-04 -1.11792545e-02  5.39058321e-03 -5.96159700e-03\n",
      "  -1.91304965e-04  1.17500122e-02 -7.47870949e-03  9.02525097e-05\n",
      "  -8.78107893e-03 -1.56434170e-03  2.56570452e-03 -9.88779049e-03]\n",
      " [-3.38821966e-03 -2.36184031e-03 -6.37655012e-03 -1.18761229e-02\n",
      "  -1.42121723e-02 -1.53495196e-03 -2.69056960e-03  2.23136679e-02\n",
      "  -2.43476758e-02  1.12726505e-03  3.70444537e-03  1.35963386e-02]\n",
      " [ 5.01857207e-03 -8.44213704e-03  9.76147160e-08  5.42352572e-03\n",
      "  -3.13508197e-03  7.71011738e-03 -1.86809065e-02  1.73118467e-02\n",
      "   1.46767801e-02 -3.35677339e-03  6.11340780e-03  4.79705919e-04]]\n",
      "layer 1, bias shape: (4, 1)\n"
     ]
    }
   ],
   "source": [
    "# weight for hidden layers\n",
    "layer_neuron = [12, 4]\n",
    "for i, neuron in enumerate(layer_neuron):\n",
    "    input_size = 784 if i == 0 else layer_neuron[i-1]\n",
    "    w[i+1] = generate_layer_weight(seed=2, neuron=neuron, input=input_size)\n",
    "    print(f'layer {i}, weight shape: {np.shape(w[i+1])}')\n",
    "    print(w[i+1])\n",
    "    b[i+1] = generate_layer_bias(seed=2, neuron=neuron)\n",
    "    print(f'layer {i}, bias shape: {np.shape(b[i+1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: train_loss = 0.5161905708996076, validate_loss = 0.42363786706345996, max_acc = 0.6925, acc = 0.6925\n",
      "epoch 2: train_loss = 0.3536492805583085, validate_loss = 0.2904536367487461, max_acc = 0.85, acc = 0.85\n",
      "epoch 3: train_loss = 0.2632947249952197, validate_loss = 0.23551573874595647, max_acc = 0.89875, acc = 0.89875\n",
      "epoch 4: train_loss = 0.20203896356033976, validate_loss = 0.16842273891162104, max_acc = 0.90875, acc = 0.90875\n",
      "epoch 5: train_loss = 0.15153446919180585, validate_loss = 0.1366400153021799, max_acc = 0.935, acc = 0.935\n",
      "epoch 6: train_loss = 0.12832562262602015, validate_loss = 0.11787197619962758, max_acc = 0.9390625, acc = 0.9390625\n",
      "epoch 7: train_loss = 0.1150746212638647, validate_loss = 0.10620711416570985, max_acc = 0.9390625, acc = 0.9384375\n",
      "epoch 8: train_loss = 0.10603949515188102, validate_loss = 0.09853355514417433, max_acc = 0.9415625, acc = 0.9415625\n",
      "epoch 9: train_loss = 0.09981405283076944, validate_loss = 0.09292449956071648, max_acc = 0.9421875, acc = 0.9421875\n",
      "epoch 10: train_loss = 0.09497295382326493, validate_loss = 0.08861099224398032, max_acc = 0.9440625, acc = 0.9440625\n",
      "epoch 11: train_loss = 0.0910788294432157, validate_loss = 0.08537319969081918, max_acc = 0.945, acc = 0.945\n",
      "epoch 12: train_loss = 0.08785494299690687, validate_loss = 0.082663404642749, max_acc = 0.9459375, acc = 0.9459375\n",
      "epoch 13: train_loss = 0.08516043228424543, validate_loss = 0.08031665782755643, max_acc = 0.9465625, acc = 0.9465625\n",
      "epoch 14: train_loss = 0.0828657810667498, validate_loss = 0.07823476864486753, max_acc = 0.948125, acc = 0.948125\n",
      "epoch 15: train_loss = 0.08081770067551403, validate_loss = 0.07628407703663342, max_acc = 0.949375, acc = 0.949375\n",
      "epoch 16: train_loss = 0.0788915151464736, validate_loss = 0.07441235193569877, max_acc = 0.9503125, acc = 0.9503125\n",
      "epoch 17: train_loss = 0.07708520675890927, validate_loss = 0.07278473099055717, max_acc = 0.9509375, acc = 0.9509375\n",
      "epoch 18: train_loss = 0.07555478544732827, validate_loss = 0.07151972725492609, max_acc = 0.95125, acc = 0.95125\n",
      "epoch 19: train_loss = 0.07431794846728904, validate_loss = 0.0705727887925658, max_acc = 0.951875, acc = 0.951875\n",
      "epoch 20: train_loss = 0.07322970549804377, validate_loss = 0.06974611093737709, max_acc = 0.9525, acc = 0.9525\n",
      "epoch 21: train_loss = 0.07218532414390784, validate_loss = 0.06899484471935356, max_acc = 0.9540625, acc = 0.9540625\n",
      "epoch 22: train_loss = 0.07119142144835527, validate_loss = 0.06829982362624587, max_acc = 0.9540625, acc = 0.9540625\n",
      "epoch 23: train_loss = 0.07024906394005655, validate_loss = 0.06764298394952041, max_acc = 0.9546875, acc = 0.9546875\n",
      "epoch 24: train_loss = 0.06935239916750038, validate_loss = 0.06703876256242747, max_acc = 0.9546875, acc = 0.9540625\n",
      "epoch 25: train_loss = 0.06850408460835868, validate_loss = 0.06649485570811707, max_acc = 0.955625, acc = 0.955625\n",
      "epoch 26: train_loss = 0.0677070918261859, validate_loss = 0.06600483925153845, max_acc = 0.9565625, acc = 0.9565625\n",
      "epoch 27: train_loss = 0.06696056651560543, validate_loss = 0.06554743725523898, max_acc = 0.9575, acc = 0.9575\n",
      "epoch 28: train_loss = 0.06625965409604506, validate_loss = 0.06509666011202252, max_acc = 0.9575, acc = 0.9575\n",
      "epoch 29: train_loss = 0.06559855197083994, validate_loss = 0.06464845941866981, max_acc = 0.9575, acc = 0.9575\n",
      "epoch 30: train_loss = 0.06497461888700214, validate_loss = 0.06422161149607777, max_acc = 0.9584375, acc = 0.9584375\n",
      "epoch 31: train_loss = 0.06438836796378006, validate_loss = 0.06383076246317713, max_acc = 0.9596875, acc = 0.9596875\n",
      "epoch 32: train_loss = 0.06384056366476658, validate_loss = 0.06347629326163984, max_acc = 0.9596875, acc = 0.9596875\n",
      "epoch 33: train_loss = 0.06333098939669729, validate_loss = 0.06315291700721852, max_acc = 0.9596875, acc = 0.9590625\n",
      "epoch 34: train_loss = 0.06285859119954723, validate_loss = 0.06286063584482035, max_acc = 0.9596875, acc = 0.959375\n",
      "epoch 35: train_loss = 0.062421385861918165, validate_loss = 0.06261112976342138, max_acc = 0.9596875, acc = 0.9590625\n",
      "epoch 36: train_loss = 0.0620172629616573, validate_loss = 0.06242020055949572, max_acc = 0.9596875, acc = 0.959375\n",
      "epoch 37: train_loss = 0.0616478725142134, validate_loss = 0.06228840481486233, max_acc = 0.9596875, acc = 0.95875\n",
      "epoch 38: train_loss = 0.06131948327969972, validate_loss = 0.06219984346392159, max_acc = 0.9596875, acc = 0.9584375\n",
      "epoch 39: train_loss = 0.061036136970406864, validate_loss = 0.06213903327347158, max_acc = 0.9596875, acc = 0.9578125\n",
      "epoch 40: train_loss = 0.0607968509918356, validate_loss = 0.06209794041469992, max_acc = 0.9596875, acc = 0.9575\n",
      "epoch 41: train_loss = 0.06059799622995117, validate_loss = 0.06207402526003427, max_acc = 0.9596875, acc = 0.9565625\n",
      "epoch 42: train_loss = 0.06043516949710967, validate_loss = 0.06206792845071156, max_acc = 0.9596875, acc = 0.9571875\n",
      "epoch 43: train_loss = 0.060303947468224796, validate_loss = 0.062081334971400344, max_acc = 0.9596875, acc = 0.9575\n",
      "epoch 44: train_loss = 0.060200328214251975, validate_loss = 0.06211486156562241, max_acc = 0.9596875, acc = 0.956875\n",
      "epoch 45: train_loss = 0.0601213996685591, validate_loss = 0.062167991029313786, max_acc = 0.9596875, acc = 0.9575\n",
      "epoch 46: train_loss = 0.06006595927141675, validate_loss = 0.06224075170067894, max_acc = 0.9596875, acc = 0.9571875\n",
      "epoch 47: train_loss = 0.06003390674082538, validate_loss = 0.062334546520893104, max_acc = 0.9596875, acc = 0.9578125\n",
      "epoch 48: train_loss = 0.06002479366870394, validate_loss = 0.06245264916408746, max_acc = 0.9596875, acc = 0.958125\n",
      "epoch 49: train_loss = 0.0600378717660612, validate_loss = 0.06259839706136745, max_acc = 0.9596875, acc = 0.9578125\n",
      "epoch 50: train_loss = 0.06007249219051885, validate_loss = 0.06277293314747828, max_acc = 0.9596875, acc = 0.9578125\n",
      "epoch 51: train_loss = 0.06012760650875313, validate_loss = 0.0629766797971677, max_acc = 0.9596875, acc = 0.9578125\n",
      "epoch 52: train_loss = 0.06020466809607062, validate_loss = 0.06320990919713465, max_acc = 0.9596875, acc = 0.9575\n",
      "epoch 53: train_loss = 0.060313202579559896, validate_loss = 0.0634751359486182, max_acc = 0.9596875, acc = 0.956875\n",
      "epoch 54: train_loss = 0.06047627915653504, validate_loss = 0.06378096457474795, max_acc = 0.9596875, acc = 0.95625\n",
      "epoch 55: train_loss = 0.060725841192615856, validate_loss = 0.06412645592986584, max_acc = 0.9596875, acc = 0.955625\n",
      "epoch 56: train_loss = 0.06108718788627059, validate_loss = 0.06451566060216755, max_acc = 0.9596875, acc = 0.9553125\n",
      "epoch 57: train_loss = 0.06157474190559828, validate_loss = 0.06498749721114513, max_acc = 0.9596875, acc = 0.9553125\n",
      "epoch 58: train_loss = 0.06218935803107624, validate_loss = 0.06558843632474795, max_acc = 0.9596875, acc = 0.9540625\n",
      "epoch 59: train_loss = 0.0628995461510562, validate_loss = 0.06634899243718259, max_acc = 0.9596875, acc = 0.9528125\n",
      "epoch 60: train_loss = 0.063693847483184, validate_loss = 0.06727509297684306, max_acc = 0.9596875, acc = 0.9521875\n",
      "epoch 61: train_loss = 0.06451783365381836, validate_loss = 0.06832347552318277, max_acc = 0.9596875, acc = 0.9503125\n",
      "epoch 62: train_loss = 0.06529180369097376, validate_loss = 0.06936012105269194, max_acc = 0.9596875, acc = 0.949375\n",
      "epoch 63: train_loss = 0.06601701236766509, validate_loss = 0.07034853859794858, max_acc = 0.9596875, acc = 0.9496875\n",
      "epoch 64: train_loss = 0.06673412375879169, validate_loss = 0.07117970454669645, max_acc = 0.9596875, acc = 0.9484375\n",
      "epoch 65: train_loss = 0.06739630454891023, validate_loss = 0.07169366329488203, max_acc = 0.9596875, acc = 0.94875\n",
      "epoch 66: train_loss = 0.06791090458920548, validate_loss = 0.0720937406030329, max_acc = 0.9596875, acc = 0.94875\n",
      "epoch 67: train_loss = 0.06846836789729499, validate_loss = 0.07262641168457938, max_acc = 0.9596875, acc = 0.94875\n",
      "epoch 68: train_loss = 0.06904520044582975, validate_loss = 0.07350196068117651, max_acc = 0.9596875, acc = 0.948125\n",
      "epoch 69: train_loss = 0.06950397865539769, validate_loss = 0.07419412362627525, max_acc = 0.9596875, acc = 0.9484375\n",
      "epoch 70: train_loss = 0.06982543112436729, validate_loss = 0.07437232884968432, max_acc = 0.9596875, acc = 0.9490625\n",
      "epoch 71: train_loss = 0.07011208953319283, validate_loss = 0.07439268201263502, max_acc = 0.9596875, acc = 0.95\n",
      "epoch 72: train_loss = 0.07027826185104119, validate_loss = 0.07437659648438236, max_acc = 0.9596875, acc = 0.9503125\n",
      "epoch 73: train_loss = 0.07014226803346857, validate_loss = 0.07430977369303716, max_acc = 0.9596875, acc = 0.951875\n",
      "epoch 74: train_loss = 0.06978162813731795, validate_loss = 0.07406331091115326, max_acc = 0.9596875, acc = 0.9515625\n",
      "epoch 75: train_loss = 0.06931683897498747, validate_loss = 0.07372459463451558, max_acc = 0.9596875, acc = 0.9521875\n",
      "epoch 76: train_loss = 0.06878927925482312, validate_loss = 0.07337323387732733, max_acc = 0.9596875, acc = 0.9525\n",
      "epoch 77: train_loss = 0.06821521432378706, validate_loss = 0.07304271650465109, max_acc = 0.9596875, acc = 0.95375\n",
      "epoch 78: train_loss = 0.06761280117367671, validate_loss = 0.07274761841026442, max_acc = 0.9596875, acc = 0.9525\n",
      "epoch 79: train_loss = 0.06700097588478761, validate_loss = 0.07250077855757504, max_acc = 0.9596875, acc = 0.9521875\n",
      "epoch 80: train_loss = 0.06638608380095468, validate_loss = 0.07229899219185659, max_acc = 0.9596875, acc = 0.953125\n",
      "epoch 81: train_loss = 0.0658000865864769, validate_loss = 0.07211242573648406, max_acc = 0.9596875, acc = 0.953125\n",
      "epoch 82: train_loss = 0.065290362729499, validate_loss = 0.07189771121893164, max_acc = 0.9596875, acc = 0.9534375\n",
      "epoch 83: train_loss = 0.06484936672802272, validate_loss = 0.07164756752728642, max_acc = 0.9596875, acc = 0.95375\n",
      "epoch 84: train_loss = 0.0644485904597199, validate_loss = 0.0713783314678556, max_acc = 0.9596875, acc = 0.9540625\n",
      "epoch 85: train_loss = 0.06406955633662031, validate_loss = 0.07110399840987608, max_acc = 0.9596875, acc = 0.9540625\n",
      "epoch 86: train_loss = 0.06370050620263858, validate_loss = 0.07082871048807429, max_acc = 0.9596875, acc = 0.9540625\n",
      "epoch 87: train_loss = 0.06333223592548348, validate_loss = 0.07054934192847206, max_acc = 0.9596875, acc = 0.95375\n",
      "epoch 88: train_loss = 0.06295606144847044, validate_loss = 0.07025981839310023, max_acc = 0.9596875, acc = 0.95375\n",
      "epoch 89: train_loss = 0.06256655631572978, validate_loss = 0.06995557150948607, max_acc = 0.9596875, acc = 0.9540625\n",
      "epoch 90: train_loss = 0.06217521016889829, validate_loss = 0.06963806213814112, max_acc = 0.9596875, acc = 0.9540625\n",
      "epoch 91: train_loss = 0.061801716203372214, validate_loss = 0.06931569507892077, max_acc = 0.9596875, acc = 0.9546875\n",
      "epoch 92: train_loss = 0.06144873089928247, validate_loss = 0.06899804767630865, max_acc = 0.9596875, acc = 0.955\n",
      "epoch 93: train_loss = 0.061116124501623265, validate_loss = 0.06869548764380765, max_acc = 0.9596875, acc = 0.9546875\n",
      "epoch 94: train_loss = 0.06080310148795039, validate_loss = 0.06841685010893354, max_acc = 0.9596875, acc = 0.9546875\n",
      "epoch 95: train_loss = 0.0605068362682897, validate_loss = 0.0681679544868536, max_acc = 0.9596875, acc = 0.9546875\n",
      "epoch 96: train_loss = 0.06022461804091137, validate_loss = 0.06795257267610792, max_acc = 0.9596875, acc = 0.9559375\n",
      "epoch 97: train_loss = 0.059954731795556694, validate_loss = 0.06777221961220087, max_acc = 0.9596875, acc = 0.9559375\n",
      "epoch 98: train_loss = 0.05969553219366531, validate_loss = 0.0676247836049949, max_acc = 0.9596875, acc = 0.9559375\n",
      "epoch 99: train_loss = 0.059446158694121, validate_loss = 0.06750352779582908, max_acc = 0.9596875, acc = 0.9565625\n",
      "epoch 100: train_loss = 0.05920713279650057, validate_loss = 0.0673997158903512, max_acc = 0.9596875, acc = 0.95625\n",
      "epoch 101: train_loss = 0.058978642343758894, validate_loss = 0.06730766853562019, max_acc = 0.9596875, acc = 0.9565625\n",
      "epoch 102: train_loss = 0.058759469596904534, validate_loss = 0.06722571550773164, max_acc = 0.9596875, acc = 0.956875\n",
      "epoch 103: train_loss = 0.058547827667117566, validate_loss = 0.06715403674631464, max_acc = 0.9596875, acc = 0.9571875\n",
      "epoch 104: train_loss = 0.05834229422123022, validate_loss = 0.06709314062000765, max_acc = 0.9596875, acc = 0.9571875\n",
      "epoch 105: train_loss = 0.05814216833471728, validate_loss = 0.06704302822805742, max_acc = 0.9596875, acc = 0.9571875\n",
      "epoch 106: train_loss = 0.05794762776747449, validate_loss = 0.06700235516346303, max_acc = 0.9596875, acc = 0.9575\n",
      "epoch 107: train_loss = 0.0577597185539902, validate_loss = 0.06696838089209646, max_acc = 0.9596875, acc = 0.9575\n",
      "epoch 108: train_loss = 0.057579851923966814, validate_loss = 0.06693862080453782, max_acc = 0.9596875, acc = 0.9571875\n",
      "epoch 109: train_loss = 0.05740896898382471, validate_loss = 0.06691256637870627, max_acc = 0.9596875, acc = 0.9578125\n",
      "epoch 110: train_loss = 0.05724707427306731, validate_loss = 0.06689113682855444, max_acc = 0.9596875, acc = 0.9578125\n",
      "epoch 111: train_loss = 0.05709336847972663, validate_loss = 0.06687488233409365, max_acc = 0.9596875, acc = 0.9578125\n",
      "epoch 112: train_loss = 0.056946615546014004, validate_loss = 0.06686304622125264, max_acc = 0.9596875, acc = 0.9578125\n",
      "epoch 113: train_loss = 0.05680547831512917, validate_loss = 0.06685367408134725, max_acc = 0.9596875, acc = 0.9578125\n",
      "epoch 114: train_loss = 0.05666878934435518, validate_loss = 0.06684411506042993, max_acc = 0.9596875, acc = 0.9578125\n",
      "epoch 115: train_loss = 0.05653576294270134, validate_loss = 0.06683164551394113, max_acc = 0.9596875, acc = 0.9578125\n",
      "epoch 116: train_loss = 0.05640610133510906, validate_loss = 0.06681427708332366, max_acc = 0.9596875, acc = 0.958125\n",
      "epoch 117: train_loss = 0.05627989636015421, validate_loss = 0.06679153208888476, max_acc = 0.9596875, acc = 0.9578125\n",
      "epoch 118: train_loss = 0.05615730990155263, validate_loss = 0.06676446905569224, max_acc = 0.9596875, acc = 0.9578125\n",
      "epoch 119: train_loss = 0.056038255339251164, validate_loss = 0.066734732746391, max_acc = 0.9596875, acc = 0.9584375\n",
      "epoch 120: train_loss = 0.05592234171110562, validate_loss = 0.06670350798100755, max_acc = 0.9596875, acc = 0.9578125\n",
      "epoch 121: train_loss = 0.0558090456373229, validate_loss = 0.0666711394006608, max_acc = 0.9596875, acc = 0.9578125\n",
      "epoch 122: train_loss = 0.055697902078581316, validate_loss = 0.0666372957221901, max_acc = 0.9596875, acc = 0.9578125\n",
      "epoch 123: train_loss = 0.055588601520617814, validate_loss = 0.06660127529421987, max_acc = 0.9596875, acc = 0.9578125\n",
      "epoch 124: train_loss = 0.055481001839263494, validate_loss = 0.066562248719014, max_acc = 0.9596875, acc = 0.9578125\n",
      "epoch 125: train_loss = 0.055375098676801605, validate_loss = 0.06651941169059192, max_acc = 0.9596875, acc = 0.9578125\n",
      "epoch 126: train_loss = 0.055270985872609, validate_loss = 0.0664720765600127, max_acc = 0.9596875, acc = 0.9584375\n",
      "epoch 127: train_loss = 0.05516881931912112, validate_loss = 0.06641972982074093, max_acc = 0.9596875, acc = 0.95875\n",
      "epoch 128: train_loss = 0.05506878721248537, validate_loss = 0.06636207167718149, max_acc = 0.9596875, acc = 0.95875\n",
      "epoch 129: train_loss = 0.054971086288285134, validate_loss = 0.06629904757714651, max_acc = 0.9596875, acc = 0.9584375\n",
      "epoch 130: train_loss = 0.054875903988767016, validate_loss = 0.06623088016406466, max_acc = 0.9596875, acc = 0.9590625\n",
      "epoch 131: train_loss = 0.05478340831841665, validate_loss = 0.06615810902075359, max_acc = 0.9596875, acc = 0.9590625\n",
      "epoch 132: train_loss = 0.05469374881138909, validate_loss = 0.06608163881153657, max_acc = 0.9596875, acc = 0.9590625\n",
      "epoch 133: train_loss = 0.05460707126119771, validate_loss = 0.06600277900249062, max_acc = 0.9596875, acc = 0.95875\n",
      "epoch 134: train_loss = 0.05452354289966371, validate_loss = 0.0659232337576134, max_acc = 0.9596875, acc = 0.95875\n",
      "epoch 135: train_loss = 0.05444337511225263, validate_loss = 0.06584498878114461, max_acc = 0.9596875, acc = 0.9584375\n",
      "epoch 136: train_loss = 0.05436682717376776, validate_loss = 0.06577006665353448, max_acc = 0.9596875, acc = 0.9590625\n",
      "epoch 137: train_loss = 0.05429418507578344, validate_loss = 0.06570017873869649, max_acc = 0.9596875, acc = 0.9590625\n",
      "epoch 138: train_loss = 0.05422572612880251, validate_loss = 0.06563635296581656, max_acc = 0.9596875, acc = 0.9590625\n",
      "epoch 139: train_loss = 0.05416168575029903, validate_loss = 0.06557863651566906, max_acc = 0.9596875, acc = 0.9596875\n",
      "epoch 140: train_loss = 0.05410223861225152, validate_loss = 0.06552597105426475, max_acc = 0.9596875, acc = 0.9596875\n",
      "epoch 141: train_loss = 0.05404751323012587, validate_loss = 0.06547633173895356, max_acc = 0.9596875, acc = 0.9596875\n",
      "epoch 142: train_loss = 0.05399767997262954, validate_loss = 0.0654271828673722, max_acc = 0.9596875, acc = 0.9596875\n",
      "epoch 143: train_loss = 0.05395313276201954, validate_loss = 0.06537615970038196, max_acc = 0.96, acc = 0.96\n",
      "epoch 144: train_loss = 0.05391465179557446, validate_loss = 0.06532164333348811, max_acc = 0.96, acc = 0.96\n",
      "epoch 145: train_loss = 0.05388327239901618, validate_loss = 0.06526281511631306, max_acc = 0.96, acc = 0.959375\n",
      "epoch 146: train_loss = 0.05385964068588152, validate_loss = 0.06519914737636548, max_acc = 0.96, acc = 0.9590625\n",
      "epoch 147: train_loss = 0.0538428720118438, validate_loss = 0.06512985129057344, max_acc = 0.96, acc = 0.9590625\n",
      "epoch 148: train_loss = 0.05382911284328481, validate_loss = 0.06505373211769691, max_acc = 0.96, acc = 0.95875\n",
      "epoch 149: train_loss = 0.053810735269280034, validate_loss = 0.06496821135798188, max_acc = 0.96, acc = 0.9590625\n",
      "epoch 150: train_loss = 0.053779348722118765, validate_loss = 0.06486642300141492, max_acc = 0.96, acc = 0.9590625\n",
      "epoch 151: train_loss = 0.05373601221663034, validate_loss = 0.06474849437541937, max_acc = 0.96, acc = 0.95875\n",
      "epoch 152: train_loss = 0.05370322848881392, validate_loss = 0.0646527847411682, max_acc = 0.96, acc = 0.9590625\n",
      "epoch 153: train_loss = 0.053719553220576616, validate_loss = 0.06461847494979851, max_acc = 0.96, acc = 0.9590625\n",
      "epoch 154: train_loss = 0.05380494082438795, validate_loss = 0.06464129160612522, max_acc = 0.96, acc = 0.9590625\n",
      "epoch 155: train_loss = 0.05394451244165358, validate_loss = 0.06471318173192973, max_acc = 0.96, acc = 0.95875\n",
      "epoch 156: train_loss = 0.05411661270973167, validate_loss = 0.0648121495638787, max_acc = 0.96, acc = 0.9584375\n",
      "epoch 157: train_loss = 0.05430457356948014, validate_loss = 0.06489231333062427, max_acc = 0.96, acc = 0.95875\n",
      "epoch 158: train_loss = 0.05449307402611586, validate_loss = 0.06491965580168715, max_acc = 0.96, acc = 0.9584375\n",
      "epoch 159: train_loss = 0.054669896036282334, validate_loss = 0.06489979383041566, max_acc = 0.96, acc = 0.958125\n",
      "epoch 160: train_loss = 0.054821240006991144, validate_loss = 0.06487071025455277, max_acc = 0.96, acc = 0.9578125\n",
      "epoch 161: train_loss = 0.05494657636432662, validate_loss = 0.0648734720644773, max_acc = 0.96, acc = 0.958125\n",
      "epoch 162: train_loss = 0.055049839506121453, validate_loss = 0.0649232960755615, max_acc = 0.96, acc = 0.9578125\n",
      "epoch 163: train_loss = 0.055116609388735756, validate_loss = 0.06498493464468241, max_acc = 0.96, acc = 0.9571875\n",
      "epoch 164: train_loss = 0.0551442430409129, validate_loss = 0.06501418627198335, max_acc = 0.96, acc = 0.9565625\n",
      "epoch 165: train_loss = 0.05513941171419941, validate_loss = 0.06501298997175238, max_acc = 0.96, acc = 0.956875\n",
      "epoch 166: train_loss = 0.05510721823085571, validate_loss = 0.06499197068742604, max_acc = 0.96, acc = 0.956875\n",
      "epoch 167: train_loss = 0.0550517423168186, validate_loss = 0.06495482493189222, max_acc = 0.96, acc = 0.9575\n",
      "epoch 168: train_loss = 0.05497156624748995, validate_loss = 0.06490302398704785, max_acc = 0.96, acc = 0.9575\n",
      "epoch 169: train_loss = 0.05486618126971383, validate_loss = 0.06483619850859537, max_acc = 0.96, acc = 0.9571875\n",
      "epoch 170: train_loss = 0.054741047567301276, validate_loss = 0.06475305718078955, max_acc = 0.96, acc = 0.9575\n",
      "epoch 171: train_loss = 0.0546042021728089, validate_loss = 0.06465398790186674, max_acc = 0.96, acc = 0.9578125\n",
      "epoch 172: train_loss = 0.05446142140450371, validate_loss = 0.06454213339522535, max_acc = 0.96, acc = 0.9578125\n",
      "epoch 173: train_loss = 0.05431597760039211, validate_loss = 0.06442177250405538, max_acc = 0.96, acc = 0.958125\n",
      "epoch 174: train_loss = 0.05417038595346316, validate_loss = 0.06429673909751756, max_acc = 0.96, acc = 0.958125\n",
      "epoch 175: train_loss = 0.054026986827504564, validate_loss = 0.06416987731550053, max_acc = 0.96, acc = 0.958125\n",
      "epoch 176: train_loss = 0.053887730655549894, validate_loss = 0.06404280323068731, max_acc = 0.96, acc = 0.958125\n",
      "epoch 177: train_loss = 0.053754072054917265, validate_loss = 0.06391576970382001, max_acc = 0.96, acc = 0.9578125\n",
      "epoch 178: train_loss = 0.0536270796399137, validate_loss = 0.06378795839303952, max_acc = 0.96, acc = 0.9578125\n",
      "epoch 179: train_loss = 0.053507545597248074, validate_loss = 0.06365825106309657, max_acc = 0.96, acc = 0.9578125\n",
      "epoch 180: train_loss = 0.05339598186837061, validate_loss = 0.0635259881507537, max_acc = 0.96, acc = 0.9578125\n",
      "epoch 181: train_loss = 0.05329255048763682, validate_loss = 0.06339120111591054, max_acc = 0.96, acc = 0.958125\n",
      "epoch 182: train_loss = 0.053197014001834415, validate_loss = 0.06325437834967955, max_acc = 0.96, acc = 0.958125\n",
      "epoch 183: train_loss = 0.05310873687010208, validate_loss = 0.06311622976415497, max_acc = 0.96, acc = 0.95875\n",
      "epoch 184: train_loss = 0.05302672870795991, validate_loss = 0.0629777560844963, max_acc = 0.96, acc = 0.9590625\n",
      "epoch 185: train_loss = 0.05294973744086003, validate_loss = 0.06284051696545546, max_acc = 0.96, acc = 0.959375\n",
      "epoch 186: train_loss = 0.052876428724930494, validate_loss = 0.06270672321887702, max_acc = 0.96, acc = 0.9590625\n",
      "epoch 187: train_loss = 0.052805604301338877, validate_loss = 0.06257888499556948, max_acc = 0.96, acc = 0.9590625\n",
      "epoch 188: train_loss = 0.052736292751244654, validate_loss = 0.062459182956516965, max_acc = 0.96, acc = 0.95875\n",
      "epoch 189: train_loss = 0.05266771843441385, validate_loss = 0.06234901371029931, max_acc = 0.96, acc = 0.95875\n",
      "epoch 190: train_loss = 0.052599313011723714, validate_loss = 0.06224894799735701, max_acc = 0.96, acc = 0.9590625\n",
      "epoch 191: train_loss = 0.05253075899996418, validate_loss = 0.06215895434215301, max_acc = 0.96, acc = 0.95875\n",
      "epoch 192: train_loss = 0.05246198236066973, validate_loss = 0.06207864963996875, max_acc = 0.96, acc = 0.959375\n",
      "epoch 193: train_loss = 0.05239309451309871, validate_loss = 0.06200747519598455, max_acc = 0.96, acc = 0.9596875\n",
      "epoch 194: train_loss = 0.052324313529923776, validate_loss = 0.06194480292124724, max_acc = 0.960625, acc = 0.960625\n",
      "epoch 195: train_loss = 0.052255886050944375, validate_loss = 0.06188999810900267, max_acc = 0.960625, acc = 0.960625\n",
      "epoch 196: train_loss = 0.052188026109797725, validate_loss = 0.061842454271518965, max_acc = 0.960625, acc = 0.9596875\n",
      "epoch 197: train_loss = 0.052120879830883544, validate_loss = 0.06180160589587827, max_acc = 0.960625, acc = 0.96\n",
      "epoch 198: train_loss = 0.05205451513157994, validate_loss = 0.061766923545579416, max_acc = 0.960625, acc = 0.96\n",
      "epoch 199: train_loss = 0.05198892894523101, validate_loss = 0.06173789880753246, max_acc = 0.960625, acc = 0.9596875\n",
      "epoch 200: train_loss = 0.05192406279056632, validate_loss = 0.06171402887085452, max_acc = 0.960625, acc = 0.9596875\n",
      "epoch 201: train_loss = 0.0518598192349396, validate_loss = 0.0616948089421972, max_acc = 0.960625, acc = 0.9596875\n",
      "epoch 202: train_loss = 0.05179607535410884, validate_loss = 0.061679735663611776, max_acc = 0.960625, acc = 0.9590625\n",
      "epoch 203: train_loss = 0.051732693032611465, validate_loss = 0.06166831904939272, max_acc = 0.960625, acc = 0.95875\n",
      "epoch 204: train_loss = 0.051669527941274065, validate_loss = 0.06166009714489995, max_acc = 0.960625, acc = 0.95875\n",
      "epoch 205: train_loss = 0.05160643848559483, validate_loss = 0.06165464791143358, max_acc = 0.960625, acc = 0.9584375\n",
      "epoch 206: train_loss = 0.051543294103582965, validate_loss = 0.06165159592455947, max_acc = 0.960625, acc = 0.9584375\n",
      "epoch 207: train_loss = 0.0514799807981108, validate_loss = 0.06165061507760566, max_acc = 0.960625, acc = 0.95875\n",
      "epoch 208: train_loss = 0.05141640148213119, validate_loss = 0.061651430489346265, max_acc = 0.960625, acc = 0.9596875\n",
      "epoch 209: train_loss = 0.05135246911492294, validate_loss = 0.061653822689672746, max_acc = 0.960625, acc = 0.9596875\n",
      "epoch 210: train_loss = 0.051288090813069204, validate_loss = 0.06165763593013525, max_acc = 0.960625, acc = 0.9603125\n",
      "epoch 211: train_loss = 0.0512231405945093, validate_loss = 0.06166279143583689, max_acc = 0.960625, acc = 0.9603125\n",
      "epoch 212: train_loss = 0.0511574177351381, validate_loss = 0.06166930548670143, max_acc = 0.960625, acc = 0.9603125\n",
      "epoch 213: train_loss = 0.05109059054304048, validate_loss = 0.061677307338221084, max_acc = 0.960625, acc = 0.96\n",
      "epoch 214: train_loss = 0.05102214295127103, validate_loss = 0.061687030238478914, max_acc = 0.960625, acc = 0.9596875\n",
      "epoch 215: train_loss = 0.05095139322283868, validate_loss = 0.061698691307298284, max_acc = 0.960625, acc = 0.9596875\n",
      "epoch 216: train_loss = 0.050877723472498394, validate_loss = 0.06171213118374272, max_acc = 0.960625, acc = 0.96\n",
      "epoch 217: train_loss = 0.05080106323804346, validate_loss = 0.06172632979686046, max_acc = 0.960625, acc = 0.96\n",
      "epoch 218: train_loss = 0.05072221331636876, validate_loss = 0.06173950828973243, max_acc = 0.960625, acc = 0.9596875\n",
      "epoch 219: train_loss = 0.050642445113583526, validate_loss = 0.06175016503367013, max_acc = 0.960625, acc = 0.9596875\n",
      "epoch 220: train_loss = 0.0505627529262909, validate_loss = 0.061757932160869604, max_acc = 0.960625, acc = 0.96\n",
      "epoch 221: train_loss = 0.0504835986099804, validate_loss = 0.06176341659592158, max_acc = 0.960625, acc = 0.96\n",
      "epoch 222: train_loss = 0.05040511130183468, validate_loss = 0.061767596648988315, max_acc = 0.960625, acc = 0.9596875\n",
      "epoch 223: train_loss = 0.050327297712123326, validate_loss = 0.06177141964351642, max_acc = 0.960625, acc = 0.9596875\n",
      "epoch 224: train_loss = 0.050250129723444885, validate_loss = 0.061775671580974786, max_acc = 0.960625, acc = 0.9596875\n",
      "epoch 225: train_loss = 0.050173564300701544, validate_loss = 0.061780976138008634, max_acc = 0.960625, acc = 0.96\n",
      "epoch 226: train_loss = 0.05009754472662844, validate_loss = 0.0617878253630298, max_acc = 0.960625, acc = 0.96\n",
      "epoch 227: train_loss = 0.050022001788293594, validate_loss = 0.061796607095887586, max_acc = 0.960625, acc = 0.96\n",
      "epoch 228: train_loss = 0.04994686006189041, validate_loss = 0.06180762081078809, max_acc = 0.960625, acc = 0.96\n",
      "epoch 229: train_loss = 0.04987204907233064, validate_loss = 0.06182107997399067, max_acc = 0.960625, acc = 0.96\n",
      "epoch 230: train_loss = 0.04979751538535866, validate_loss = 0.06183710004925613, max_acc = 0.960625, acc = 0.96\n",
      "epoch 231: train_loss = 0.049723228696650044, validate_loss = 0.06185567329737344, max_acc = 0.960625, acc = 0.9596875\n",
      "epoch 232: train_loss = 0.049649174728433894, validate_loss = 0.061876635911923, max_acc = 0.960625, acc = 0.9596875\n",
      "epoch 233: train_loss = 0.04957533312604479, validate_loss = 0.061899637615018016, max_acc = 0.960625, acc = 0.9596875\n",
      "epoch 234: train_loss = 0.049501648965294666, validate_loss = 0.06192412429776637, max_acc = 0.960625, acc = 0.9596875\n",
      "epoch 235: train_loss = 0.04942801424739935, validate_loss = 0.06194933931783995, max_acc = 0.960625, acc = 0.9596875\n",
      "epoch 236: train_loss = 0.049354271802031634, validate_loss = 0.061974344275993534, max_acc = 0.960625, acc = 0.9596875\n",
      "epoch 237: train_loss = 0.0492802400691032, validate_loss = 0.061998062590892564, max_acc = 0.960625, acc = 0.9596875\n",
      "epoch 238: train_loss = 0.04920574649789103, validate_loss = 0.062019357824132204, max_acc = 0.960625, acc = 0.959375\n",
      "epoch 239: train_loss = 0.0491306602792617, validate_loss = 0.06203716333954667, max_acc = 0.960625, acc = 0.959375\n",
      "epoch 240: train_loss = 0.049054929401497215, validate_loss = 0.0620506703213686, max_acc = 0.960625, acc = 0.9590625\n",
      "epoch 241: train_loss = 0.04897863995658969, validate_loss = 0.062059557637182204, max_acc = 0.960625, acc = 0.9590625\n",
      "epoch 242: train_loss = 0.04890211014590368, validate_loss = 0.062064214683987394, max_acc = 0.960625, acc = 0.9596875\n",
      "epoch 243: train_loss = 0.048825989355169463, validate_loss = 0.06206584485428221, max_acc = 0.960625, acc = 0.96\n",
      "epoch 244: train_loss = 0.04875125885324362, validate_loss = 0.0620662527718614, max_acc = 0.960625, acc = 0.960625\n",
      "epoch 245: train_loss = 0.048679013676010914, validate_loss = 0.06206723498296877, max_acc = 0.960625, acc = 0.960625\n",
      "epoch 246: train_loss = 0.04861007274551751, validate_loss = 0.06206993659808106, max_acc = 0.960625, acc = 0.960625\n",
      "epoch 247: train_loss = 0.04854470306911019, validate_loss = 0.06207470663484278, max_acc = 0.960625, acc = 0.960625\n",
      "epoch 248: train_loss = 0.04848268109583459, validate_loss = 0.062081436707671196, max_acc = 0.960625, acc = 0.960625\n",
      "epoch 249: train_loss = 0.04842356479609162, validate_loss = 0.062089926925963435, max_acc = 0.9609375, acc = 0.9609375\n",
      "epoch 250: train_loss = 0.04836691591442459, validate_loss = 0.062100041653831664, max_acc = 0.96125, acc = 0.96125\n",
      "epoch 251: train_loss = 0.04831238347521026, validate_loss = 0.06211171827247523, max_acc = 0.96125, acc = 0.96125\n",
      "epoch 252: train_loss = 0.04825970266349345, validate_loss = 0.06212493373568229, max_acc = 0.96125, acc = 0.96125\n",
      "epoch 253: train_loss = 0.04820867039162668, validate_loss = 0.062139674342968895, max_acc = 0.961875, acc = 0.961875\n",
      "epoch 254: train_loss = 0.04815912351776259, validate_loss = 0.06215591646302003, max_acc = 0.961875, acc = 0.961875\n",
      "epoch 255: train_loss = 0.04811092414654012, validate_loss = 0.062173615637823115, max_acc = 0.961875, acc = 0.961875\n",
      "epoch 256: train_loss = 0.04806395017883349, validate_loss = 0.06219270124701988, max_acc = 0.961875, acc = 0.9615625\n",
      "epoch 257: train_loss = 0.04801808906708191, validate_loss = 0.06221307517463084, max_acc = 0.961875, acc = 0.9615625\n",
      "epoch 258: train_loss = 0.04797323366031615, validate_loss = 0.062234613654025564, max_acc = 0.961875, acc = 0.9615625\n",
      "epoch 259: train_loss = 0.04792927967959043, validate_loss = 0.062257171643518745, max_acc = 0.9621875, acc = 0.9621875\n",
      "epoch 260: train_loss = 0.04788612462349808, validate_loss = 0.062280588980557265, max_acc = 0.9621875, acc = 0.9621875\n",
      "epoch 261: train_loss = 0.047843667919584346, validate_loss = 0.06230469740343862, max_acc = 0.9621875, acc = 0.9621875\n",
      "epoch 262: train_loss = 0.04780181206056202, validate_loss = 0.06232932746722028, max_acc = 0.9621875, acc = 0.961875\n",
      "epoch 263: train_loss = 0.047760464388782654, validate_loss = 0.062354314489663464, max_acc = 0.9621875, acc = 0.9621875\n",
      "epoch 264: train_loss = 0.04771953916397823, validate_loss = 0.06237950293797359, max_acc = 0.9621875, acc = 0.9621875\n",
      "epoch 265: train_loss = 0.04767895957909154, validate_loss = 0.06240474903731285, max_acc = 0.9621875, acc = 0.9621875\n",
      "epoch 266: train_loss = 0.047638659466097334, validate_loss = 0.06242992175099114, max_acc = 0.9621875, acc = 0.9621875\n",
      "epoch 267: train_loss = 0.04759858453510026, validate_loss = 0.06245490256865404, max_acc = 0.9621875, acc = 0.9621875\n",
      "epoch 268: train_loss = 0.04755869308886988, validate_loss = 0.062479584700113035, max_acc = 0.9621875, acc = 0.9621875\n",
      "epoch 269: train_loss = 0.04751895622822037, validate_loss = 0.0625038723032459, max_acc = 0.9621875, acc = 0.9621875\n",
      "epoch 270: train_loss = 0.04747935759823536, validate_loss = 0.06252768028988337, max_acc = 0.9621875, acc = 0.9621875\n",
      "epoch 271: train_loss = 0.04743989272267081, validate_loss = 0.06255093507381398, max_acc = 0.9621875, acc = 0.9621875\n",
      "epoch 272: train_loss = 0.047400567950581715, validate_loss = 0.06257357637144195, max_acc = 0.9621875, acc = 0.9621875\n",
      "epoch 273: train_loss = 0.04736139902242873, validate_loss = 0.06259555987023205, max_acc = 0.9625, acc = 0.9625\n",
      "epoch 274: train_loss = 0.04732240927902286, validate_loss = 0.062616860297032, max_acc = 0.9625, acc = 0.9625\n",
      "epoch 275: train_loss = 0.04728362759549358, validate_loss = 0.06263747422309413, max_acc = 0.9625, acc = 0.9625\n",
      "epoch 276: train_loss = 0.04724508620587235, validate_loss = 0.06265742190878491, max_acc = 0.9625, acc = 0.9625\n",
      "epoch 277: train_loss = 0.04720681864957035, validate_loss = 0.06267674765252244, max_acc = 0.9625, acc = 0.9625\n",
      "epoch 278: train_loss = 0.047168858075438067, validate_loss = 0.06269551842978814, max_acc = 0.9625, acc = 0.9625\n",
      "epoch 279: train_loss = 0.047131236066882846, validate_loss = 0.06271382098738303, max_acc = 0.9625, acc = 0.9625\n",
      "epoch 280: train_loss = 0.047093982028170965, validate_loss = 0.06273175786893517, max_acc = 0.9628125, acc = 0.9628125\n",
      "epoch 281: train_loss = 0.04705712304839141, validate_loss = 0.06274944299543905, max_acc = 0.9628125, acc = 0.9628125\n",
      "epoch 282: train_loss = 0.04702068408027384, validate_loss = 0.06276699738465759, max_acc = 0.9628125, acc = 0.9628125\n",
      "epoch 283: train_loss = 0.04698468825156746, validate_loss = 0.06278454541043331, max_acc = 0.9628125, acc = 0.9628125\n",
      "epoch 284: train_loss = 0.04694915715367437, validate_loss = 0.06280221176081162, max_acc = 0.9628125, acc = 0.9628125\n",
      "epoch 285: train_loss = 0.046914111000210805, validate_loss = 0.06282011903550704, max_acc = 0.9628125, acc = 0.9628125\n",
      "epoch 286: train_loss = 0.046879568596775244, validate_loss = 0.06283838578525484, max_acc = 0.9628125, acc = 0.9628125\n",
      "epoch 287: train_loss = 0.04684554710427239, validate_loss = 0.06285712475972595, max_acc = 0.9628125, acc = 0.9628125\n",
      "epoch 288: train_loss = 0.04681206161250832, validate_loss = 0.06287644118802367, max_acc = 0.9628125, acc = 0.9628125\n",
      "epoch 289: train_loss = 0.046779124571186256, validate_loss = 0.06289643103543333, max_acc = 0.9628125, acc = 0.9628125\n",
      "epoch 290: train_loss = 0.046746745151307785, validate_loss = 0.0629171793187703, max_acc = 0.9628125, acc = 0.9628125\n",
      "epoch 291: train_loss = 0.046714928626806485, validate_loss = 0.06293875867516183, max_acc = 0.9628125, acc = 0.9628125\n",
      "epoch 292: train_loss = 0.046683675868383796, validate_loss = 0.06296122842971533, max_acc = 0.9634375, acc = 0.9634375\n",
      "epoch 293: train_loss = 0.04665298302652147, validate_loss = 0.06298463438021824, max_acc = 0.9634375, acc = 0.9634375\n",
      "epoch 294: train_loss = 0.04662284145157481, validate_loss = 0.06300900941934767, max_acc = 0.9634375, acc = 0.9634375\n",
      "epoch 295: train_loss = 0.04659323786365947, validate_loss = 0.06303437497375315, max_acc = 0.9634375, acc = 0.9634375\n",
      "epoch 296: train_loss = 0.04656415475324551, validate_loss = 0.0630607430899442, max_acc = 0.9634375, acc = 0.9634375\n",
      "epoch 297: train_loss = 0.046535570971999, validate_loss = 0.06308811887043596, max_acc = 0.9634375, acc = 0.9634375\n",
      "epoch 298: train_loss = 0.04650746246445207, validate_loss = 0.06311650288052882, max_acc = 0.9634375, acc = 0.9634375\n",
      "epoch 299: train_loss = 0.046479803091641576, validate_loss = 0.06314589311661475, max_acc = 0.9634375, acc = 0.963125\n",
      "epoch 300: train_loss = 0.04645256550225306, validate_loss = 0.06317628615702488, max_acc = 0.9634375, acc = 0.963125\n",
      "epoch 301: train_loss = 0.0464257220100042, validate_loss = 0.06320767721401455, max_acc = 0.9634375, acc = 0.963125\n",
      "epoch 302: train_loss = 0.046399245436070775, validate_loss = 0.06324005897943236, max_acc = 0.9634375, acc = 0.963125\n",
      "epoch 303: train_loss = 0.04637310987452734, validate_loss = 0.06327341940568483, max_acc = 0.9634375, acc = 0.9628125\n",
      "epoch 304: train_loss = 0.0463472913421264, validate_loss = 0.06330773885758863, max_acc = 0.9634375, acc = 0.9625\n",
      "epoch 305: train_loss = 0.04632176828625636, validate_loss = 0.06334298733656946, max_acc = 0.9634375, acc = 0.9625\n",
      "epoch 306: train_loss = 0.046296521947802996, validate_loss = 0.06337912261117792, max_acc = 0.9634375, acc = 0.9625\n",
      "epoch 307: train_loss = 0.04627153660433292, validate_loss = 0.06341608999470853, max_acc = 0.9634375, acc = 0.9625\n",
      "epoch 308: train_loss = 0.0462467997436089, validate_loss = 0.06345382417462564, max_acc = 0.9634375, acc = 0.9628125\n",
      "epoch 309: train_loss = 0.04622230222675533, validate_loss = 0.06349225301225576, max_acc = 0.9634375, acc = 0.9628125\n",
      "epoch 310: train_loss = 0.04619803848676263, validate_loss = 0.063531302766082, max_acc = 0.9634375, acc = 0.9628125\n",
      "epoch 311: train_loss = 0.04617400677082416, validate_loss = 0.06357090391066961, max_acc = 0.9634375, acc = 0.9628125\n",
      "epoch 312: train_loss = 0.0461502093803097, validate_loss = 0.06361099669607331, max_acc = 0.9634375, acc = 0.9621875\n",
      "epoch 313: train_loss = 0.046126652799254896, validate_loss = 0.06365153577427016, max_acc = 0.9634375, acc = 0.961875\n",
      "epoch 314: train_loss = 0.04610334754081255, validate_loss = 0.06369249349254757, max_acc = 0.9634375, acc = 0.961875\n",
      "epoch 315: train_loss = 0.04608030749145492, validate_loss = 0.06373386169849647, max_acc = 0.9634375, acc = 0.9615625\n",
      "epoch 316: train_loss = 0.04605754851024155, validate_loss = 0.06377565204242941, max_acc = 0.9634375, acc = 0.9615625\n",
      "epoch 317: train_loss = 0.04603508607107689, validate_loss = 0.06381789478499175, max_acc = 0.9634375, acc = 0.9615625\n",
      "epoch 318: train_loss = 0.046012931856037206, validate_loss = 0.06386063605568731, max_acc = 0.9634375, acc = 0.9615625\n",
      "epoch 319: train_loss = 0.04599108945283202, validate_loss = 0.06390393343507444, max_acc = 0.9634375, acc = 0.9621875\n",
      "epoch 320: train_loss = 0.04596954968317334, validate_loss = 0.06394784974691677, max_acc = 0.9634375, acc = 0.9621875\n",
      "epoch 321: train_loss = 0.04594828652167918, validate_loss = 0.06399244514284641, max_acc = 0.9634375, acc = 0.9621875\n",
      "epoch 322: train_loss = 0.045927254886316514, validate_loss = 0.06403776798578877, max_acc = 0.9634375, acc = 0.9621875\n",
      "epoch 323: train_loss = 0.04590639155353782, validate_loss = 0.06408384561688535, max_acc = 0.9634375, acc = 0.9621875\n",
      "epoch 324: train_loss = 0.045885619895168074, validate_loss = 0.06413067660085253, max_acc = 0.9634375, acc = 0.961875\n",
      "epoch 325: train_loss = 0.04586485810106039, validate_loss = 0.06417822617662156, max_acc = 0.9634375, acc = 0.961875\n",
      "epoch 326: train_loss = 0.04584402940176373, validate_loss = 0.0642264261696111, max_acc = 0.9634375, acc = 0.961875\n",
      "epoch 327: train_loss = 0.04582307206500757, validate_loss = 0.06427517959832206, max_acc = 0.9634375, acc = 0.9615625\n",
      "epoch 328: train_loss = 0.0458019469830373, validate_loss = 0.0643243689979659, max_acc = 0.9634375, acc = 0.9615625\n",
      "epoch 329: train_loss = 0.04578064146477065, validate_loss = 0.06437386659361023, max_acc = 0.9634375, acc = 0.9615625\n",
      "epoch 330: train_loss = 0.04575916899367003, validate_loss = 0.06442354423447508, max_acc = 0.9634375, acc = 0.96125\n",
      "epoch 331: train_loss = 0.045737565709077145, validate_loss = 0.06447328145027843, max_acc = 0.9634375, acc = 0.96125\n",
      "epoch 332: train_loss = 0.04571588490322658, validate_loss = 0.06452297080884978, max_acc = 0.9634375, acc = 0.96125\n",
      "epoch 333: train_loss = 0.045694190868249135, validate_loss = 0.06457252055893606, max_acc = 0.9634375, acc = 0.96125\n",
      "epoch 334: train_loss = 0.04567255313917961, validate_loss = 0.06462185507665077, max_acc = 0.9634375, acc = 0.96125\n",
      "epoch 335: train_loss = 0.04565104176686712, validate_loss = 0.06467091383867431, max_acc = 0.9634375, acc = 0.96125\n",
      "epoch 336: train_loss = 0.04562972387052379, validate_loss = 0.06471964960202213, max_acc = 0.9634375, acc = 0.9615625\n",
      "epoch 337: train_loss = 0.04560866143444662, validate_loss = 0.06476802630590736, max_acc = 0.9634375, acc = 0.9615625\n",
      "epoch 338: train_loss = 0.04558791013609322, validate_loss = 0.06481601702910728, max_acc = 0.9634375, acc = 0.96125\n",
      "epoch 339: train_loss = 0.045567518900987404, validate_loss = 0.06486360219175082, max_acc = 0.9634375, acc = 0.96125\n",
      "epoch 340: train_loss = 0.045547529844718486, validate_loss = 0.06491076809822961, max_acc = 0.9634375, acc = 0.96125\n",
      "epoch 341: train_loss = 0.045527978261597664, validate_loss = 0.06495750586838996, max_acc = 0.9634375, acc = 0.9609375\n",
      "epoch 342: train_loss = 0.04550889234446671, validate_loss = 0.06500381077799224, max_acc = 0.9634375, acc = 0.960625\n",
      "epoch 343: train_loss = 0.04549029237631104, validate_loss = 0.06504968200636141, max_acc = 0.9634375, acc = 0.960625\n",
      "epoch 344: train_loss = 0.04547218923842952, validate_loss = 0.06509512275320976, max_acc = 0.9634375, acc = 0.960625\n",
      "epoch 345: train_loss = 0.04545458225050432, validate_loss = 0.06514014063029189, max_acc = 0.9634375, acc = 0.9603125\n",
      "epoch 346: train_loss = 0.045437456597595516, validate_loss = 0.06518474816281809, max_acc = 0.9634375, acc = 0.9603125\n",
      "epoch 347: train_loss = 0.04542078087162862, validate_loss = 0.06522896317322649, max_acc = 0.9634375, acc = 0.9603125\n",
      "epoch 348: train_loss = 0.04540450547180537, validate_loss = 0.06527280880179162, max_acc = 0.9634375, acc = 0.9603125\n",
      "epoch 349: train_loss = 0.045388562646153104, validate_loss = 0.06531631297703144, max_acc = 0.9634375, acc = 0.9603125\n",
      "epoch 350: train_loss = 0.04537286871923283, validate_loss = 0.06535950728798481, max_acc = 0.9634375, acc = 0.9603125\n",
      "epoch 351: train_loss = 0.045357328551248056, validate_loss = 0.06540242538918939, max_acc = 0.9634375, acc = 0.9603125\n",
      "epoch 352: train_loss = 0.04534184166916085, validate_loss = 0.0654451012144373, max_acc = 0.9634375, acc = 0.9603125\n",
      "epoch 353: train_loss = 0.04532630904287631, validate_loss = 0.06548756732293672, max_acc = 0.9634375, acc = 0.9603125\n",
      "epoch 354: train_loss = 0.045310639340782, validate_loss = 0.06552985363738956, max_acc = 0.9634375, acc = 0.9603125\n",
      "epoch 355: train_loss = 0.04529475372009301, validate_loss = 0.06557198669962902, max_acc = 0.9634375, acc = 0.9603125\n",
      "epoch 356: train_loss = 0.045278588657281175, validate_loss = 0.06561398943163857, max_acc = 0.9634375, acc = 0.9603125\n",
      "epoch 357: train_loss = 0.04526209680398373, validate_loss = 0.06565588129696716, max_acc = 0.9634375, acc = 0.9603125\n",
      "epoch 358: train_loss = 0.04524524620857686, validate_loss = 0.06569767872338357, max_acc = 0.9634375, acc = 0.9603125\n",
      "epoch 359: train_loss = 0.045228018413138005, validate_loss = 0.06573939565816193, max_acc = 0.9634375, acc = 0.9603125\n",
      "epoch 360: train_loss = 0.0452104059428561, validate_loss = 0.065781044159595, max_acc = 0.9634375, acc = 0.9603125\n",
      "epoch 361: train_loss = 0.0451924096123757, validate_loss = 0.06582263496373478, max_acc = 0.9634375, acc = 0.9603125\n",
      "epoch 362: train_loss = 0.045174035943518376, validate_loss = 0.06586417799433242, max_acc = 0.9634375, acc = 0.9603125\n",
      "epoch 363: train_loss = 0.045155294864401944, validate_loss = 0.06590568280398046, max_acc = 0.9634375, acc = 0.96\n",
      "epoch 364: train_loss = 0.04513619776223221, validate_loss = 0.0659471589466669, max_acc = 0.9634375, acc = 0.96\n",
      "epoch 365: train_loss = 0.0451167558959569, validate_loss = 0.06598861628857802, max_acc = 0.9634375, acc = 0.9596875\n",
      "epoch 366: train_loss = 0.045096979136602544, validate_loss = 0.06603006526708019, max_acc = 0.9634375, acc = 0.9596875\n",
      "epoch 367: train_loss = 0.045076874985383666, validate_loss = 0.0660715171089014, max_acc = 0.9634375, acc = 0.9596875\n",
      "epoch 368: train_loss = 0.04505644781540881, validate_loss = 0.06611298401858498, max_acc = 0.9634375, acc = 0.9596875\n",
      "epoch 369: train_loss = 0.04503569828627065, validate_loss = 0.06615447934790533, max_acc = 0.9634375, acc = 0.9596875\n",
      "epoch 370: train_loss = 0.045014622887993655, validate_loss = 0.06619601775646106, max_acc = 0.9634375, acc = 0.9596875\n",
      "epoch 371: train_loss = 0.044993213579112144, validate_loss = 0.06623761537323737, max_acc = 0.9634375, acc = 0.9596875\n",
      "epoch 372: train_loss = 0.044971457491722315, validate_loss = 0.06627928996864556, max_acc = 0.9634375, acc = 0.9596875\n",
      "epoch 373: train_loss = 0.04494933668353116, validate_loss = 0.06632106114630014, max_acc = 0.9634375, acc = 0.9596875\n",
      "epoch 374: train_loss = 0.044926827923200664, validate_loss = 0.06636295056350026, max_acc = 0.9634375, acc = 0.959375\n",
      "epoch 375: train_loss = 0.044903902500876766, validate_loss = 0.0664049821887638, max_acc = 0.9634375, acc = 0.959375\n",
      "epoch 376: train_loss = 0.04488052606139391, validate_loss = 0.0664471826033966, max_acc = 0.9634375, acc = 0.959375\n",
      "epoch 377: train_loss = 0.04485665846404257, validate_loss = 0.06648958135130494, max_acc = 0.9634375, acc = 0.959375\n",
      "epoch 378: train_loss = 0.04483225368127294, validate_loss = 0.06653221133590348, max_acc = 0.9634375, acc = 0.959375\n",
      "epoch 379: train_loss = 0.04480725976098492, validate_loss = 0.06657510925322202, max_acc = 0.9634375, acc = 0.959375\n",
      "epoch 380: train_loss = 0.044781618895555646, validate_loss = 0.06661831603310539, max_acc = 0.9634375, acc = 0.9590625\n",
      "epoch 381: train_loss = 0.04475526766895533, validate_loss = 0.06666187723093389, max_acc = 0.9634375, acc = 0.9590625\n",
      "epoch 382: train_loss = 0.04472813759599844, validate_loss = 0.06670584326306152, max_acc = 0.9634375, acc = 0.95875\n",
      "epoch 383: train_loss = 0.044700156131522, validate_loss = 0.06675026929897002, max_acc = 0.9634375, acc = 0.95875\n",
      "epoch 384: train_loss = 0.04467124842007044, validate_loss = 0.06679521449667385, max_acc = 0.9634375, acc = 0.958125\n",
      "epoch 385: train_loss = 0.044641340186703946, validate_loss = 0.06684074007704677, max_acc = 0.9634375, acc = 0.9578125\n",
      "epoch 386: train_loss = 0.04461036234037088, validate_loss = 0.06688690546408524, max_acc = 0.9634375, acc = 0.9578125\n",
      "epoch 387: train_loss = 0.04457825806024002, validate_loss = 0.06693376138401082, max_acc = 0.9634375, acc = 0.9578125\n",
      "epoch 388: train_loss = 0.04454499330821221, validate_loss = 0.06698133850375368, max_acc = 0.9634375, acc = 0.958125\n",
      "epoch 389: train_loss = 0.04451057171585976, validate_loss = 0.0670296301523446, max_acc = 0.9634375, acc = 0.958125\n",
      "epoch 390: train_loss = 0.044475054336979666, validate_loss = 0.06707856845139169, max_acc = 0.9634375, acc = 0.958125\n",
      "epoch 391: train_loss = 0.044438583348997016, validate_loss = 0.06712799565940357, max_acc = 0.9634375, acc = 0.958125\n",
      "epoch 392: train_loss = 0.0444014058697554, validate_loss = 0.06717763752632396, max_acc = 0.9634375, acc = 0.958125\n",
      "epoch 393: train_loss = 0.044363889581545565, validate_loss = 0.06722709233647002, max_acc = 0.9634375, acc = 0.958125\n",
      "epoch 394: train_loss = 0.044326517500187596, validate_loss = 0.06727585375840432, max_acc = 0.9634375, acc = 0.958125\n",
      "epoch 395: train_loss = 0.04428984946190821, validate_loss = 0.06732337925322004, max_acc = 0.9634375, acc = 0.958125\n",
      "epoch 396: train_loss = 0.04425444815184083, validate_loss = 0.06736919334762981, max_acc = 0.9634375, acc = 0.958125\n",
      "epoch 397: train_loss = 0.0442207871811424, validate_loss = 0.06741298743173191, max_acc = 0.9634375, acc = 0.9578125\n",
      "epoch 398: train_loss = 0.04418917504311365, validate_loss = 0.0674546710551768, max_acc = 0.9634375, acc = 0.9578125\n",
      "epoch 399: train_loss = 0.044159724964368305, validate_loss = 0.06749435659346043, max_acc = 0.9634375, acc = 0.9578125\n",
      "epoch 400: train_loss = 0.0441323763220111, validate_loss = 0.0675322969001331, max_acc = 0.9634375, acc = 0.9578125\n",
      "epoch 401: train_loss = 0.044106948432554624, validate_loss = 0.06756881185317902, max_acc = 0.9634375, acc = 0.9578125\n",
      "epoch 402: train_loss = 0.04408320002898058, validate_loss = 0.06760422982687808, max_acc = 0.9634375, acc = 0.9578125\n",
      "epoch 403: train_loss = 0.04406087633389685, validate_loss = 0.06763885217043743, max_acc = 0.9634375, acc = 0.9571875\n",
      "epoch 404: train_loss = 0.04403973815333545, validate_loss = 0.06767293716749463, max_acc = 0.9634375, acc = 0.9571875\n",
      "epoch 405: train_loss = 0.044019575525628116, validate_loss = 0.06770669653873107, max_acc = 0.9634375, acc = 0.9571875\n",
      "epoch 406: train_loss = 0.044000211131770176, validate_loss = 0.06774029851000524, max_acc = 0.9634375, acc = 0.9571875\n",
      "epoch 407: train_loss = 0.04398149818737517, validate_loss = 0.06777387352596405, max_acc = 0.9634375, acc = 0.9571875\n",
      "epoch 408: train_loss = 0.043963316051520006, validate_loss = 0.0678075204320228, max_acc = 0.9634375, acc = 0.9571875\n",
      "epoch 409: train_loss = 0.043945565405081446, validate_loss = 0.06784131209002568, max_acc = 0.9634375, acc = 0.9571875\n",
      "epoch 410: train_loss = 0.04392816389206506, validate_loss = 0.06787530004657824, max_acc = 0.9634375, acc = 0.9571875\n",
      "epoch 411: train_loss = 0.04391104255308845, validate_loss = 0.06790951821124479, max_acc = 0.9634375, acc = 0.9571875\n",
      "epoch 412: train_loss = 0.043894143088353266, validate_loss = 0.06794398565940443, max_acc = 0.9634375, acc = 0.9571875\n",
      "epoch 413: train_loss = 0.04387741585627776, validate_loss = 0.06797870873703281, max_acc = 0.9634375, acc = 0.9571875\n",
      "epoch 414: train_loss = 0.04386081846743572, validate_loss = 0.06801368266023056, max_acc = 0.9634375, acc = 0.9571875\n",
      "epoch 415: train_loss = 0.04384431482771075, validate_loss = 0.06804889279507596, max_acc = 0.9634375, acc = 0.9571875\n",
      "epoch 416: train_loss = 0.04382787449770805, validate_loss = 0.06808431578340354, max_acc = 0.9634375, acc = 0.9571875\n",
      "epoch 417: train_loss = 0.04381147225778917, validate_loss = 0.06811992065025047, max_acc = 0.9634375, acc = 0.9571875\n",
      "epoch 418: train_loss = 0.0437950877950345, validate_loss = 0.06815566998959748, max_acc = 0.9634375, acc = 0.9575\n",
      "epoch 419: train_loss = 0.0437787054562799, validate_loss = 0.06819152127831338, max_acc = 0.9634375, acc = 0.9575\n",
      "epoch 420: train_loss = 0.04376231403533798, validate_loss = 0.06822742831865315, max_acc = 0.9634375, acc = 0.9578125\n",
      "epoch 421: train_loss = 0.04374590657827717, validate_loss = 0.06826334276466692, max_acc = 0.9634375, acc = 0.9578125\n",
      "epoch 422: train_loss = 0.04372948019611894, validate_loss = 0.06829921565570224, max_acc = 0.9634375, acc = 0.9578125\n",
      "epoch 423: train_loss = 0.043713035871695366, validate_loss = 0.0683349988665701, max_acc = 0.9634375, acc = 0.9578125\n",
      "epoch 424: train_loss = 0.04369657824203298, validate_loss = 0.06837064638997363, max_acc = 0.9634375, acc = 0.9578125\n",
      "epoch 425: train_loss = 0.043680115335374775, validate_loss = 0.06840611538830703, max_acc = 0.9634375, acc = 0.9578125\n",
      "epoch 426: train_loss = 0.043663658246235686, validate_loss = 0.068441366981518, max_acc = 0.9634375, acc = 0.958125\n",
      "epoch 427: train_loss = 0.04364722074217402, validate_loss = 0.06847636676749458, max_acc = 0.9634375, acc = 0.958125\n",
      "epoch 428: train_loss = 0.043630818808908046, validate_loss = 0.06851108509548468, max_acc = 0.9634375, acc = 0.958125\n",
      "epoch 429: train_loss = 0.04361447015181371, validate_loss = 0.0685454971286216, max_acc = 0.9634375, acc = 0.958125\n",
      "epoch 430: train_loss = 0.0435981936787222, validate_loss = 0.0685795827387235, max_acc = 0.9634375, acc = 0.958125\n",
      "epoch 431: train_loss = 0.04358200899030893, validate_loss = 0.06861332627692049, max_acc = 0.9634375, acc = 0.958125\n",
      "epoch 432: train_loss = 0.04356593590107223, validate_loss = 0.06864671625968916, max_acc = 0.9634375, acc = 0.958125\n",
      "epoch 433: train_loss = 0.04354999400768582, validate_loss = 0.06867974500369503, max_acc = 0.9634375, acc = 0.958125\n",
      "epoch 434: train_loss = 0.04353420231436938, validate_loss = 0.06871240823604234, max_acc = 0.9634375, acc = 0.958125\n",
      "epoch 435: train_loss = 0.043518578918329116, validate_loss = 0.06874470470004602, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 436: train_loss = 0.04350314075323374, validate_loss = 0.06877663577099971, max_acc = 0.9634375, acc = 0.95875\n",
      "epoch 437: train_loss = 0.043487903385414486, validate_loss = 0.068808205091751, max_acc = 0.9634375, acc = 0.95875\n",
      "epoch 438: train_loss = 0.04347288085590534, validate_loss = 0.06883941823424108, max_acc = 0.9634375, acc = 0.95875\n",
      "epoch 439: train_loss = 0.04345808556124344, validate_loss = 0.06887028239042162, max_acc = 0.9634375, acc = 0.95875\n",
      "epoch 440: train_loss = 0.04344352816665225, validate_loss = 0.06890080609400381, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 441: train_loss = 0.04342921754641374, validate_loss = 0.06893099897317521, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 442: train_loss = 0.04341516074755045, validate_loss = 0.06896087153359637, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 443: train_loss = 0.04340136297407977, validate_loss = 0.06899043497046008, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 444: train_loss = 0.0433878275900099, validate_loss = 0.06901970100802426, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 445: train_loss = 0.04337455613977979, validate_loss = 0.06904868176460673, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 446: train_loss = 0.043361548385105315, validate_loss = 0.06907738964044526, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 447: train_loss = 0.04334880235727342, validate_loss = 0.0691058372249018, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 448: train_loss = 0.04333631442391781, validate_loss = 0.0691340372181224, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 449: train_loss = 0.043324079369464294, validate_loss = 0.06916200236035194, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 450: train_loss = 0.043312090488893194, validate_loss = 0.06918974535949307, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 451: train_loss = 0.043300339695478154, validate_loss = 0.06921727880407105, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 452: train_loss = 0.043288817644999575, validate_loss = 0.06924461504433993, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 453: train_loss = 0.0432775138818697, validate_loss = 0.06927176601875579, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 454: train_loss = 0.04326641701698408, validate_loss = 0.06929874299646847, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 455: train_loss = 0.04325551495325475, validate_loss = 0.06932555619943154, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 456: train_loss = 0.04324479518285168, validate_loss = 0.06935221426160497, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 457: train_loss = 0.043234245190024036, validate_loss = 0.06937872348077796, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 458: train_loss = 0.04322385300380835, validate_loss = 0.0694050868265224, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 459: train_loss = 0.04321360795290659, validate_loss = 0.06943130269510299, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 460: train_loss = 0.04320350167377065, validate_loss = 0.06945736346131551, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 461: train_loss = 0.04319352940010281, validate_loss = 0.06948325398072702, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 462: train_loss = 0.04318369149836198, validate_loss = 0.06950895034627048, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 463: train_loss = 0.04317399508779067, validate_loss = 0.06953441937527009, max_acc = 0.9634375, acc = 0.958125\n",
      "epoch 464: train_loss = 0.043164455387448154, validate_loss = 0.06955961942078054, max_acc = 0.9634375, acc = 0.958125\n",
      "epoch 465: train_loss = 0.04315509620885165, validate_loss = 0.06958450303159767, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 466: train_loss = 0.0431459488928933, validate_loss = 0.06960902158677616, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 467: train_loss = 0.043137049184998964, validate_loss = 0.06963313128276352, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 468: train_loss = 0.04312843220488314, validate_loss = 0.06965679900679209, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 469: train_loss = 0.04312012664456542, validate_loss = 0.06968000620414905, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 470: train_loss = 0.043112150064364814, validate_loss = 0.06970274929379124, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 471: train_loss = 0.043104507030397116, validate_loss = 0.06972503644488327, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 472: train_loss = 0.04309719076694573, validate_loss = 0.06974688192421576, max_acc = 0.9634375, acc = 0.95875\n",
      "epoch 473: train_loss = 0.0430901876270194, validate_loss = 0.06976829996861236, max_acc = 0.9634375, acc = 0.95875\n",
      "epoch 474: train_loss = 0.043083482839090796, validate_loss = 0.06978929993129859, max_acc = 0.9634375, acc = 0.95875\n",
      "epoch 475: train_loss = 0.04307706599279817, validate_loss = 0.06980988362364453, max_acc = 0.9634375, acc = 0.95875\n",
      "epoch 476: train_loss = 0.04307093530412188, validate_loss = 0.06983004488726308, max_acc = 0.9634375, acc = 0.95875\n",
      "epoch 477: train_loss = 0.043065100372995185, validate_loss = 0.06984977086401076, max_acc = 0.9634375, acc = 0.95875\n",
      "epoch 478: train_loss = 0.0430595836060956, validate_loss = 0.06986904425048676, max_acc = 0.9634375, acc = 0.95875\n",
      "epoch 479: train_loss = 0.043054420664851996, validate_loss = 0.06988784590446145, max_acc = 0.9634375, acc = 0.95875\n",
      "epoch 480: train_loss = 0.043049660293037036, validate_loss = 0.0699061573548471, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 481: train_loss = 0.04304536378285847, validate_loss = 0.06992396294699475, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 482: train_loss = 0.04304160422514875, validate_loss = 0.06994125148690931, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 483: train_loss = 0.04303846559169781, validate_loss = 0.06995801732933182, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 484: train_loss = 0.04303604162226481, validate_loss = 0.06997426090236344, max_acc = 0.9634375, acc = 0.958125\n",
      "epoch 485: train_loss = 0.043034434426771156, validate_loss = 0.0699899886964906, max_acc = 0.9634375, acc = 0.9578125\n",
      "epoch 486: train_loss = 0.043033752650061284, validate_loss = 0.07000521278724042, max_acc = 0.9634375, acc = 0.9578125\n",
      "epoch 487: train_loss = 0.04303410896782136, validate_loss = 0.07001995002314175, max_acc = 0.9634375, acc = 0.9578125\n",
      "epoch 488: train_loss = 0.0430356165789569, validate_loss = 0.07003422110465488, max_acc = 0.9634375, acc = 0.958125\n",
      "epoch 489: train_loss = 0.04303838423574158, validate_loss = 0.07004804990952591, max_acc = 0.9634375, acc = 0.958125\n",
      "epoch 490: train_loss = 0.04304250923461421, validate_loss = 0.07006146357721432, max_acc = 0.9634375, acc = 0.958125\n",
      "epoch 491: train_loss = 0.04304806773771246, validate_loss = 0.07007449401717512, max_acc = 0.9634375, acc = 0.958125\n",
      "epoch 492: train_loss = 0.04305510191115641, validate_loss = 0.07008718158175807, max_acc = 0.9634375, acc = 0.958125\n",
      "epoch 493: train_loss = 0.04306360379261188, validate_loss = 0.07009958152730719, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 494: train_loss = 0.043073496682869, validate_loss = 0.07011177343274158, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 495: train_loss = 0.04308461625713718, validate_loss = 0.07012387284993216, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 496: train_loss = 0.04309669535846292, validate_loss = 0.07013604318056399, max_acc = 0.9634375, acc = 0.95875\n",
      "epoch 497: train_loss = 0.04310935806935526, validate_loss = 0.07014850444922249, max_acc = 0.9634375, acc = 0.95875\n",
      "epoch 498: train_loss = 0.04312212930485412, validate_loss = 0.0701615349102228, max_acc = 0.9634375, acc = 0.95875\n",
      "epoch 499: train_loss = 0.043134464862547885, validate_loss = 0.07017546200837321, max_acc = 0.9634375, acc = 0.95875\n",
      "epoch 500: train_loss = 0.04314580302106445, validate_loss = 0.07019064147682147, max_acc = 0.9634375, acc = 0.95875\n",
      "epoch 501: train_loss = 0.0431556327638686, validate_loss = 0.07020742687557663, max_acc = 0.9634375, acc = 0.95875\n",
      "epoch 502: train_loss = 0.043163567095198856, validate_loss = 0.07022613537883408, max_acc = 0.9634375, acc = 0.95875\n",
      "epoch 503: train_loss = 0.043169405195817794, validate_loss = 0.07024701746816002, max_acc = 0.9634375, acc = 0.9590625\n",
      "epoch 504: train_loss = 0.04317316688531042, validate_loss = 0.07027023720130363, max_acc = 0.9634375, acc = 0.9590625\n",
      "epoch 505: train_loss = 0.043175088447800464, validate_loss = 0.07029586592913549, max_acc = 0.9634375, acc = 0.9590625\n",
      "epoch 506: train_loss = 0.04317557948357281, validate_loss = 0.07032388728594588, max_acc = 0.9634375, acc = 0.9590625\n",
      "epoch 507: train_loss = 0.04317515239475544, validate_loss = 0.0703542076600833, max_acc = 0.9634375, acc = 0.95875\n",
      "epoch 508: train_loss = 0.04317434405479298, validate_loss = 0.07038666643035218, max_acc = 0.9634375, acc = 0.95875\n",
      "epoch 509: train_loss = 0.04317364920303455, validate_loss = 0.0704210437431354, max_acc = 0.9634375, acc = 0.95875\n",
      "epoch 510: train_loss = 0.04317347750457002, validate_loss = 0.07045706730400234, max_acc = 0.9634375, acc = 0.95875\n",
      "epoch 511: train_loss = 0.04317413564772951, validate_loss = 0.07049442056676218, max_acc = 0.9634375, acc = 0.95875\n",
      "epoch 512: train_loss = 0.043175828128654496, validate_loss = 0.07053275331554298, max_acc = 0.9634375, acc = 0.95875\n",
      "epoch 513: train_loss = 0.04317866864174467, validate_loss = 0.070571694558137, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 514: train_loss = 0.04318269682882133, validate_loss = 0.070610867716819, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 515: train_loss = 0.04318789844652739, validate_loss = 0.07064990797376823, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 516: train_loss = 0.043194228045166504, validate_loss = 0.07068848046767648, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 517: train_loss = 0.04320163235292813, validate_loss = 0.07072629663308412, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 518: train_loss = 0.04321007154839689, validate_loss = 0.07076312549032732, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 519: train_loss = 0.043219535675779665, validate_loss = 0.070798797501948, max_acc = 0.9634375, acc = 0.958125\n",
      "epoch 520: train_loss = 0.043230054603458495, validate_loss = 0.0708332002681957, max_acc = 0.9634375, acc = 0.958125\n",
      "epoch 521: train_loss = 0.04324170149188033, validate_loss = 0.07086626709968047, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 522: train_loss = 0.043254591067487726, validate_loss = 0.07089796075741298, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 523: train_loss = 0.04326887474884941, validate_loss = 0.07092825509230327, max_acc = 0.9634375, acc = 0.9584375\n",
      "epoch 524: train_loss = 0.043284734806842924, validate_loss = 0.07095711702566229, max_acc = 0.9634375, acc = 0.958125\n",
      "epoch 525: train_loss = 0.04330237941730962, validate_loss = 0.07098449064155844, max_acc = 0.9634375, acc = 0.9578125\n",
      "epoch 526: train_loss = 0.04332203989052792, validate_loss = 0.07101028453192644, max_acc = 0.9634375, acc = 0.9578125\n",
      "epoch 527: train_loss = 0.04334397072290207, validate_loss = 0.0710343632478962, max_acc = 0.9634375, acc = 0.9578125\n",
      "epoch 528: train_loss = 0.043368452557045155, validate_loss = 0.07105654387372773, max_acc = 0.9634375, acc = 0.9578125\n",
      "epoch 529: train_loss = 0.04339579776618864, validate_loss = 0.07107659929016498, max_acc = 0.9634375, acc = 0.9578125\n",
      "epoch 530: train_loss = 0.04342635825294172, validate_loss = 0.07109427042850651, max_acc = 0.9634375, acc = 0.9575\n",
      "epoch 531: train_loss = 0.04346053509223987, validate_loss = 0.07110929033309416, max_acc = 0.9634375, acc = 0.9575\n",
      "epoch 532: train_loss = 0.043498789501628575, validate_loss = 0.07112142237171608, max_acc = 0.9634375, acc = 0.9575\n",
      "epoch 533: train_loss = 0.04354165355508221, validate_loss = 0.07113051214668652, max_acc = 0.9634375, acc = 0.9575\n",
      "epoch 534: train_loss = 0.04358973612286049, validate_loss = 0.07113654597570022, max_acc = 0.9634375, acc = 0.9571875\n",
      "epoch 535: train_loss = 0.043643714442329395, validate_loss = 0.07113969778109368, max_acc = 0.9634375, acc = 0.9571875\n",
      "epoch 536: train_loss = 0.04370429673761356, validate_loss = 0.07114033484225607, max_acc = 0.9634375, acc = 0.9571875\n",
      "epoch 537: train_loss = 0.04377214244112155, validate_loss = 0.07113895446640338, max_acc = 0.9634375, acc = 0.9571875\n",
      "epoch 538: train_loss = 0.04384773983053007, validate_loss = 0.0711360619920416, max_acc = 0.9634375, acc = 0.956875\n",
      "epoch 539: train_loss = 0.043931262340283814, validate_loss = 0.07113208692252936, max_acc = 0.9634375, acc = 0.956875\n",
      "epoch 540: train_loss = 0.04402244051085162, validate_loss = 0.07112749748208531, max_acc = 0.9634375, acc = 0.9571875\n",
      "epoch 541: train_loss = 0.04412049465680541, validate_loss = 0.07112313384291644, max_acc = 0.9634375, acc = 0.9575\n",
      "epoch 542: train_loss = 0.04422418034775604, validate_loss = 0.07112041804600788, max_acc = 0.9634375, acc = 0.9575\n",
      "epoch 543: train_loss = 0.04433196896183226, validate_loss = 0.07112102475203305, max_acc = 0.9634375, acc = 0.9575\n",
      "epoch 544: train_loss = 0.04444230958421214, validate_loss = 0.07112620085655692, max_acc = 0.9634375, acc = 0.9578125\n",
      "epoch 545: train_loss = 0.044553912402294706, validate_loss = 0.07113636304681366, max_acc = 0.9634375, acc = 0.9575\n",
      "epoch 546: train_loss = 0.0446659876988294, validate_loss = 0.07115110667161403, max_acc = 0.9634375, acc = 0.9575\n",
      "epoch 547: train_loss = 0.04477817843315571, validate_loss = 0.07116927181084827, max_acc = 0.9634375, acc = 0.9575\n",
      "epoch 548: train_loss = 0.044889921555323245, validate_loss = 0.07118904085329064, max_acc = 0.9634375, acc = 0.9575\n",
      "epoch 549: train_loss = 0.04499952548354564, validate_loss = 0.07120856548643975, max_acc = 0.9634375, acc = 0.956875\n",
      "epoch 550: train_loss = 0.045103968175764, validate_loss = 0.07122754908944284, max_acc = 0.9634375, acc = 0.9565625\n",
      "epoch 551: train_loss = 0.045200311661428565, validate_loss = 0.07124899957362606, max_acc = 0.9634375, acc = 0.95625\n",
      "epoch 552: train_loss = 0.045288101758296444, validate_loss = 0.07127868529271213, max_acc = 0.9634375, acc = 0.95625\n",
      "epoch 553: train_loss = 0.04537056741826916, validate_loss = 0.07132121891345022, max_acc = 0.9634375, acc = 0.9559375\n",
      "epoch 554: train_loss = 0.045452971698952044, validate_loss = 0.07137611397289978, max_acc = 0.9634375, acc = 0.9553125\n",
      "epoch 555: train_loss = 0.045539628084118516, validate_loss = 0.07143759979660314, max_acc = 0.9634375, acc = 0.9553125\n",
      "epoch 556: train_loss = 0.045631753984629826, validate_loss = 0.0714976984581826, max_acc = 0.9634375, acc = 0.9553125\n",
      "epoch 557: train_loss = 0.04572738601066659, validate_loss = 0.07155049354926059, max_acc = 0.9634375, acc = 0.9553125\n",
      "epoch 558: train_loss = 0.04582588805955732, validate_loss = 0.07159608332057436, max_acc = 0.9634375, acc = 0.9553125\n",
      "epoch 559: train_loss = 0.04593301448805875, validate_loss = 0.07164113290660351, max_acc = 0.9634375, acc = 0.955\n",
      "epoch 560: train_loss = 0.04605934676525566, validate_loss = 0.07169601036705903, max_acc = 0.9634375, acc = 0.955\n",
      "epoch 561: train_loss = 0.04621364285594069, validate_loss = 0.0717682846774946, max_acc = 0.9634375, acc = 0.9546875\n",
      "epoch 562: train_loss = 0.04639405172761122, validate_loss = 0.07185072635552552, max_acc = 0.9634375, acc = 0.9546875\n",
      "epoch 563: train_loss = 0.04659008091958865, validate_loss = 0.07191740570891003, max_acc = 0.9634375, acc = 0.9546875\n",
      "epoch 564: train_loss = 0.046804880869162215, validate_loss = 0.0719585196160704, max_acc = 0.9634375, acc = 0.9546875\n",
      "epoch 565: train_loss = 0.04704439182713505, validate_loss = 0.07200428356329355, max_acc = 0.9634375, acc = 0.955\n",
      "epoch 566: train_loss = 0.04730257569452243, validate_loss = 0.0720886174771271, max_acc = 0.9634375, acc = 0.9553125\n",
      "epoch 567: train_loss = 0.047581025035859766, validate_loss = 0.07226219165960515, max_acc = 0.9634375, acc = 0.955\n",
      "epoch 568: train_loss = 0.04785113849316763, validate_loss = 0.07257770070376694, max_acc = 0.9634375, acc = 0.954375\n",
      "epoch 569: train_loss = 0.048095722583855596, validate_loss = 0.07298160858163792, max_acc = 0.9634375, acc = 0.95625\n",
      "epoch 570: train_loss = 0.048339656958932685, validate_loss = 0.07331628502290197, max_acc = 0.9634375, acc = 0.95625\n",
      "epoch 571: train_loss = 0.0486157831566845, validate_loss = 0.07355499753345544, max_acc = 0.9634375, acc = 0.955\n",
      "epoch 572: train_loss = 0.048916994528770276, validate_loss = 0.07371699395466583, max_acc = 0.9634375, acc = 0.95375\n",
      "epoch 573: train_loss = 0.04920477313434584, validate_loss = 0.07381696566415118, max_acc = 0.9634375, acc = 0.9540625\n",
      "epoch 574: train_loss = 0.049481682924276384, validate_loss = 0.07387348104748509, max_acc = 0.9634375, acc = 0.95375\n",
      "epoch 575: train_loss = 0.04978639866229909, validate_loss = 0.07393491661819271, max_acc = 0.9634375, acc = 0.9540625\n",
      "epoch 576: train_loss = 0.05015703995385943, validate_loss = 0.07409762336711129, max_acc = 0.9634375, acc = 0.9534375\n",
      "epoch 577: train_loss = 0.050618838356225854, validate_loss = 0.07438467062738609, max_acc = 0.9634375, acc = 0.9534375\n",
      "epoch 578: train_loss = 0.051175896534682144, validate_loss = 0.0746698399239401, max_acc = 0.9634375, acc = 0.9528125\n",
      "epoch 579: train_loss = 0.051735337623213126, validate_loss = 0.07489043526728073, max_acc = 0.9634375, acc = 0.9521875\n",
      "epoch 580: train_loss = 0.052241270518438875, validate_loss = 0.07505823318845063, max_acc = 0.9634375, acc = 0.9521875\n",
      "epoch 581: train_loss = 0.05270839410443303, validate_loss = 0.07520466633803811, max_acc = 0.9634375, acc = 0.9525\n",
      "epoch 582: train_loss = 0.05321389240637476, validate_loss = 0.07534281305156115, max_acc = 0.9634375, acc = 0.9515625\n",
      "epoch 583: train_loss = 0.0537486238706479, validate_loss = 0.07544947288560398, max_acc = 0.9634375, acc = 0.9515625\n",
      "epoch 584: train_loss = 0.05421604217289661, validate_loss = 0.0756051063659093, max_acc = 0.9634375, acc = 0.9515625\n",
      "epoch 585: train_loss = 0.054675049876101174, validate_loss = 0.07593691163535446, max_acc = 0.9634375, acc = 0.9534375\n",
      "epoch 586: train_loss = 0.05511298170125031, validate_loss = 0.0764044531747778, max_acc = 0.9634375, acc = 0.9528125\n",
      "epoch 587: train_loss = 0.05549776494041339, validate_loss = 0.07698823130492782, max_acc = 0.9634375, acc = 0.9525\n",
      "epoch 588: train_loss = 0.05591450312439121, validate_loss = 0.07763892115514988, max_acc = 0.9634375, acc = 0.9534375\n",
      "epoch 589: train_loss = 0.05637024577862064, validate_loss = 0.07799846929504028, max_acc = 0.9634375, acc = 0.9528125\n",
      "epoch 590: train_loss = 0.05670997038087946, validate_loss = 0.0782514219713572, max_acc = 0.9634375, acc = 0.9515625\n",
      "epoch 591: train_loss = 0.056943956081369436, validate_loss = 0.07870337204682878, max_acc = 0.9634375, acc = 0.9503125\n",
      "epoch 592: train_loss = 0.057228730521847425, validate_loss = 0.0792472748270737, max_acc = 0.9634375, acc = 0.95\n",
      "epoch 593: train_loss = 0.05751006255843933, validate_loss = 0.0798816833246963, max_acc = 0.9634375, acc = 0.94875\n",
      "epoch 594: train_loss = 0.05779584812170527, validate_loss = 0.08057068768284383, max_acc = 0.9634375, acc = 0.948125\n",
      "========== stop because overfitting ==========\n"
     ]
    }
   ],
   "source": [
    "epoch_num = 1000\n",
    "validate_size = len(validate_target)\n",
    "train_size = len(train_target)\n",
    "best_w = {} # weight of layers\n",
    "best_b = {} # bias of layers\n",
    "best_epoch = 0\n",
    "best_train_loss = 0\n",
    "best_validate_loss = 0\n",
    "max_acc = 0\n",
    "overfit_threshold = 0.015 # 如果 acc 比 max_acc 小 overfit_threshold 的话\n",
    "is_overfit = False\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    train_loss_sum = 0\n",
    "    oneline_log(f'epoch {epoch + 1}')\n",
    "    \n",
    "    for i, feature_data in enumerate(train_feature):\n",
    "        # 第 i 笔 data 的 feature\n",
    "        a = {} # output of layers\n",
    "        error = {} # error of layers\n",
    "        a[0] = feature_data\n",
    "\n",
    "        # Forward\n",
    "        for layer, neuron in enumerate(layer_neuron):\n",
    "            output = model.forward(a[layer], w[layer+1], b[layer+1])            \n",
    "            a[layer+1] = np.array(output.reshape(1,-1))[0]\n",
    "\n",
    "        # Backward\n",
    "        y = one_hot(train_target[i][0])\n",
    "        loss_estimate = a[len(layer_neuron)]\n",
    "        train_loss_sum += criterion.forward(loss_estimate, y)\n",
    "        \n",
    "        error[len(layer_neuron)] = np.mat(loss_estimate - y).T\n",
    "\n",
    "        for layer in range(len(layer_neuron) - 1, -1, -1):\n",
    "            # print(f'layer: {layer}')\n",
    "            left = np.mat(w[layer+1]).T\n",
    "            right = error[layer+1] * np.dot( a[layer], 1-a[layer])\n",
    "            error[layer] = np.dot(left , right)\n",
    "            # print(f'error {layer}: {error[layer]}')\n",
    "\n",
    "        # Update parameter\n",
    "        for layer in range(1, len(layer_neuron)+1):\n",
    "            dw = np.dot(error[layer] , np.mat(a[layer-1]))\n",
    "            w[layer] -= learning_rate * dw\n",
    "            b[layer] -= learning_rate * error[layer]\n",
    "\n",
    "    train_loss = train_loss_sum / train_size\n",
    "\n",
    "    if (epoch+1) % 1 == 0:\n",
    "        acc_count = 0\n",
    "        validate_loss_sum = 0\n",
    "        \n",
    "        for i, feature_data in enumerate(validate_feature):\n",
    "            a = {} # output of layers\n",
    "            error = {} # error of layers\n",
    "            a[0] = feature_data\n",
    "\n",
    "            # Forward\n",
    "            for layer, neuron in enumerate(layer_neuron):\n",
    "                output = model.forward(a[layer], w[layer+1], b[layer+1])            \n",
    "                a[layer+1] = np.array(output.reshape(1,-1))[0]\n",
    "\n",
    "            arr = a[len(layer_neuron)]\n",
    "\n",
    "            y = one_hot(validate_target[i][0])\n",
    "         \n",
    "            for i, data in enumerate(y):\n",
    "                if data == 1 and arr[i] == np.max(arr):\n",
    "                    acc_count += 1\n",
    "            # Backward\n",
    "            loss_estimate = a[len(layer_neuron)]\n",
    "            validate_loss_sum += criterion.forward(loss_estimate, y)\n",
    "        \n",
    "        validate_loss = validate_loss_sum / validate_size\n",
    "        if(max_acc < acc_count):\n",
    "            max_acc = acc_count\n",
    "            best_b = b\n",
    "            best_w = w\n",
    "            best_epoch = epoch\n",
    "            best_train_loss = train_loss\n",
    "            best_validate_loss = validate_loss\n",
    "        oneline_log('')\n",
    "        print(f'epoch {epoch + 1}: train_loss = {train_loss}, validate_loss = {validate_loss}, max_acc = {max_acc/validate_size}, acc = {acc_count/validate_size}')\n",
    "    \n",
    "    if max_acc/validate_size - acc_count/validate_size > overfit_threshold and epoch > 100:\n",
    "        is_overfit = True\n",
    "        print('========== stop because overfitting ==========')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting: layer=2, neuron=[12, 4]\n",
      "best result at epoch 292: train_loss = 0.046683675868383796, validate_loss = 0.06296122842971533, acc = 0.9634375\n"
     ]
    }
   ],
   "source": [
    "print(f'setting: layer={len(layer_neuron)}, neuron={layer_neuron}')\n",
    "print(f'best result at epoch {best_epoch + 1}: train_loss = {best_train_loss}, validate_loss = {best_validate_loss}, acc = {max_acc/validate_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_test_origin = pd.read_csv('data/lab3_test.csv')\n",
    "# pd_test_origin = pd_test_origin / 255\n",
    "pd_test_origin = np.array(pd_test_origin)\n",
    "pd_test_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = []\n",
    "for i, feature_data in enumerate(pd_test_origin):\n",
    "    a = {} # output of layers\n",
    "    error = {} # error of layers\n",
    "    a[0] = feature_data\n",
    "\n",
    "    # Forward\n",
    "    for layer, neuron in enumerate(layer_neuron):\n",
    "        output = model.forward(a[layer], best_w[layer+1], best_b[layer+1])            \n",
    "        a[layer+1] = np.array(output.reshape(1,-1))[0]\n",
    "\n",
    "    arr = a[len(layer_neuron)]\n",
    "\n",
    "    for i, data in enumerate(arr):\n",
    "        if data == np.max(arr):\n",
    "            if i == 0:\n",
    "                ans.append(0)\n",
    "            elif i == 1:\n",
    "                ans.append(3)\n",
    "            elif i == 2:\n",
    "                ans.append(8)\n",
    "            elif i == 3:\n",
    "                ans.append(9)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " ...]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ans = pd.DataFrame(ans)\n",
    "test_ans = test_ans.rename({0:'ans'},axis=1)\n",
    "test_ans.to_csv('test_ans.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1bd4997df8f250b7ce125c4f296e41cc30fc4467602168a8546b0db04b01c027"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
