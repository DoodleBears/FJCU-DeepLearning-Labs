{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneline_log(text):\n",
    "    sys.stdout.write('\\r')\n",
    "    sys.stdout.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression():\n",
    "    def __init__(self):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "\n",
    "    def linear(self, x, w, b):\n",
    "\n",
    "        return w * x.T + b\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "\n",
    "        x = np.clip(x, -709.78, 709.78)\n",
    "\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def forward(self, x, w, b):\n",
    "        x = np.mat(x)\n",
    "        w = np.mat(w)\n",
    "        # print(f'x shape: {np.shape(x)}')\n",
    "        # print(f'w shape: {np.shape(w)}')\n",
    "        net_input = self.linear(x, w, b)\n",
    "        # print(f'net_input: {net_input}')\n",
    "        y_estimate = self.sigmoid(net_input)\n",
    "\n",
    "        return y_estimate\n",
    "\n",
    "\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CrossEntropy\n",
    "class BinaryCrossEntropy():\n",
    "    def __init__(self):\n",
    "        super(BinaryCrossEntropy, self).__init__()\n",
    "    \n",
    "    def cross_entropy(self, y_pred, target):\n",
    "        x = target*np.log(y_pred) + (1-target)*np.log(1-y_pred)\n",
    "\n",
    "        return -(np.mean(x))\n",
    "\n",
    "    def forward(self, y_pred, target):\n",
    "\n",
    "        return self.cross_entropy(y_pred, target)\n",
    "criterion = BinaryCrossEntropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Function: Cross-entropy loss\n",
    "# used to calculate the loss of estimate\n",
    "# a: estimate value of y\n",
    "# y: true value of y\n",
    "def calculate_cross_entropy(y, a):\n",
    "    return -np.nan_to_num(np.multiply(y, np.log(a)) + np.multiply((1-y), np.log(1-a))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate random weight for each layer\n",
    "# number of weight = input * neuron of next layer\n",
    "\n",
    "# return value is 2D array of weight w_ji \n",
    "# w_ji means for the j neuron, the weight of input i\n",
    "random_scalar = 100\n",
    "def generate_layer_weight(seed, neuron, input):\n",
    "    np.random.seed(seed) # set seed for weight random\n",
    "    # w_ji 其中 j 对应 neuron, i 对应 input，所以 reshape 也同样按照如此进行\n",
    "    weight = np.random.randn(neuron,input) / random_scalar\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate random bias for each layer\n",
    "# number of bias = neuron of layer\n",
    "\n",
    "# return value is vector of bias\n",
    "def generate_layer_bias(seed, neuron):\n",
    "    np.random.seed(seed) # set seed for bias random\n",
    "    bias = np.random.randn(neuron, 1) / random_scalar\n",
    "    return bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(value):\n",
    "    if value == 9:\n",
    "        return np.array([0,0,0,1])\n",
    "    elif value == 8:\n",
    "        return np.array([0,0,1,0])\n",
    "    elif value == 3:\n",
    "        return np.array([0,1,0,0])\n",
    "    elif value == 0:\n",
    "        return np.array([1,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('================== Start ==================')\n",
    "pd_train_origin = pd.read_csv('data/lab3_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保留 label 为 0、3、8、9 的 data\n",
    "# 用 drop() 的方法，参见: https://www.cnblogs.com/everfight/p/pandas_condition_remove.html\n",
    "pd_train_origin = pd_train_origin[(pd_train_origin.label == 0) \n",
    "                                | (pd_train_origin.label == 3) \n",
    "                                | (pd_train_origin.label == 8) \n",
    "                                | (pd_train_origin.label == 9) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_train = pd_train_origin.sample(frac=0.9, random_state=2)\n",
    "pd_validate = pd_train_origin.drop(index=pd_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3200 entries, 1 to 15994\n",
      "Columns: 785 entries, label to pixel784\n",
      "dtypes: int64(785)\n",
      "memory usage: 19.2 MB\n"
     ]
    }
   ],
   "source": [
    "pd_validate.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12800 entries, 464 to 13599\n",
      "Columns: 785 entries, label to pixel784\n",
      "dtypes: int64(785)\n",
      "memory usage: 76.8 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7199</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>202</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3303</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>158</td>\n",
       "      <td>147</td>\n",
       "      <td>199</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "464       9       0       0       0       0       0       0       0       0   \n",
       "7199      3       0       0       0       0       0       0       0       0   \n",
       "3303      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "      pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "464        0  ...         0         0         2         0         0       255   \n",
       "7199       0  ...       202        19         0         5         0         0   \n",
       "3303       0  ...       158       147       199        72         0         3   \n",
       "\n",
       "      pixel781  pixel782  pixel783  pixel784  \n",
       "464         99         0         0         0  \n",
       "7199         0         0         0         0  \n",
       "3303         0         0         0         0  \n",
       "\n",
       "[3 rows x 785 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_train.info()\n",
    "pd_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = pd_train.drop(['label'], axis=1)\n",
    "train_feature = train_feature / 255\n",
    "train_target = pd.DataFrame(pd_train.label)\n",
    "train_feature = np.array(train_feature)\n",
    "train_target = np.array(train_target)\n",
    "\n",
    "validate_feature = pd_validate.drop(['label'], axis=1)\n",
    "validate_feature = validate_feature / 255\n",
    "validate_target = pd.DataFrame(pd_validate.label)\n",
    "validate_feature = np.array(validate_feature)\n",
    "validate_target = np.array(validate_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一共 len(train_feature) 笔 data\n",
    "# 每一笔 data 有 784 个 pixel\n",
    "\n",
    "w = {} # weight of layers\n",
    "b = {} # bias of layers\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 0, weight shape: (32, 784)\n",
      "layer 0, bias shape: (32, 1)\n",
      "layer 1, weight shape: (4, 32)\n",
      "layer 1, bias shape: (4, 1)\n"
     ]
    }
   ],
   "source": [
    "# weight for hidden layers\n",
    "layer_neuron = [32, 4]\n",
    "for i, neuron in enumerate(layer_neuron):\n",
    "    input_size = 784 if i == 0 else layer_neuron[i-1]\n",
    "    w[i+1] = generate_layer_weight(seed=1, neuron=neuron, input=input_size)\n",
    "    print(f'layer {i}, weight shape: {np.shape(w[i+1])}')\n",
    "    \n",
    "    b[i+1] = generate_layer_bias(seed=1, neuron=neuron)\n",
    "    print(f'layer {i}, bias shape: {np.shape(b[i+1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10: train_loss = 0.18353670922257798, validate_loss = 0.1749036753538387, acc = 0.9265625\n",
      "epoch 20: train_loss = 0.10803005294737736, validate_loss = 0.10485830698539612, acc = 0.935625\n",
      "epoch 30: train_loss = 0.0893320216368268, validate_loss = 0.08548196457166247, acc = 0.9475\n",
      "epoch 40: train_loss = 0.08121930007980244, validate_loss = 0.07711239091319053, acc = 0.951875\n",
      "epoch 50: train_loss = 0.07651736790516547, validate_loss = 0.07259174186739042, acc = 0.9540625\n",
      "epoch 60: train_loss = 0.07329841873273554, validate_loss = 0.06971562050010391, acc = 0.95625\n",
      "epoch 70: train_loss = 0.0708423265217568, validate_loss = 0.06769326875701244, acc = 0.9559375\n",
      "epoch 80: train_loss = 0.06883384780876613, validate_loss = 0.06618677201152283, acc = 0.9565625\n",
      "epoch 90: train_loss = 0.0671169417066069, validate_loss = 0.0650226784274705, acc = 0.95625\n",
      "epoch 100: train_loss = 0.0656080679585435, validate_loss = 0.0641055792563055, acc = 0.955625\n",
      "epoch 110: train_loss = 0.0642645718084193, validate_loss = 0.06338503165762285, acc = 0.9559375\n",
      "epoch 120: train_loss = 0.06306263391086686, validate_loss = 0.06282043516681314, acc = 0.95625\n",
      "epoch 130: train_loss = 0.06198728100357578, validate_loss = 0.06236801608016579, acc = 0.9571875\n"
     ]
    }
   ],
   "source": [
    "epoch_num = 130\n",
    "validate_size = len(validate_target)\n",
    "train_size = len(train_target)\n",
    "best_w = {} # weight of layers\n",
    "best_b = {} # bias of layers\n",
    "best_epoch = 0\n",
    "best_train_loss = 0\n",
    "best_validate_loss = 0\n",
    "max_acc = 0\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    train_loss_sum = 0\n",
    "    for i, feature_data in enumerate(train_feature):\n",
    "        # 第 i 笔 data 的 feature\n",
    "        a = {} # output of layers\n",
    "        error = {} # error of layers\n",
    "        a[0] = feature_data\n",
    "\n",
    "        # Forward\n",
    "        for layer, neuron in enumerate(layer_neuron):\n",
    "            output = model.forward(a[layer], w[layer+1], b[layer+1])            \n",
    "            a[layer+1] = np.array(output.reshape(1,-1))[0]\n",
    "\n",
    "        # Backward\n",
    "        y = one_hot(train_target[i][0])\n",
    "        loss_estimate = a[len(layer_neuron)]\n",
    "        train_loss_sum += criterion.forward(loss_estimate, y)\n",
    "        \n",
    "        error[len(layer_neuron)] = np.mat(loss_estimate - y).T\n",
    "\n",
    "        for layer in range(len(layer_neuron) - 1, -1, -1):\n",
    "            # print(f'layer: {layer}')\n",
    "            left = np.mat(w[layer+1]).T\n",
    "            right = error[layer+1] * np.dot( a[layer], 1-a[layer])\n",
    "            error[layer] = np.dot(left , right)\n",
    "            # print(f'error {layer}: {error[layer]}')\n",
    "\n",
    "        # Update parameter\n",
    "        for layer in range(1, len(layer_neuron)+1):\n",
    "            dw = np.dot(error[layer] , np.mat(a[layer-1]))\n",
    "            w[layer] -= learning_rate * dw\n",
    "            b[layer] -= learning_rate * error[layer]\n",
    "\n",
    "    train_loss = train_loss_sum / train_size\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        acc_count = 0\n",
    "        validate_loss_sum = 0\n",
    "        \n",
    "        for i, feature_data in enumerate(validate_feature):\n",
    "            a = {} # output of layers\n",
    "            error = {} # error of layers\n",
    "            a[0] = feature_data\n",
    "\n",
    "            # Forward\n",
    "            for layer, neuron in enumerate(layer_neuron):\n",
    "                output = model.forward(a[layer], w[layer+1], b[layer+1])            \n",
    "                a[layer+1] = np.array(output.reshape(1,-1))[0]\n",
    "\n",
    "            arr = a[len(layer_neuron)]\n",
    "\n",
    "            y = one_hot(validate_target[i][0])\n",
    "         \n",
    "            for i, data in enumerate(y):\n",
    "                if data == 1 and arr[i] == np.max(arr):\n",
    "                    acc_count += 1\n",
    "            # Backward\n",
    "            loss_estimate = a[len(layer_neuron)]\n",
    "            validate_loss_sum += criterion.forward(loss_estimate, y)\n",
    "        \n",
    "        validate_loss = validate_loss_sum / validate_size\n",
    "        if(max_acc < acc_count):\n",
    "            max_acc = acc_count\n",
    "            best_b = b\n",
    "            best_w = w\n",
    "            best_epoch = epoch\n",
    "            best_train_loss = train_loss\n",
    "            best_validate_loss = validate_loss\n",
    "        print(f'epoch {epoch + 1}: train_loss = {train_loss}, validate_loss = {validate_loss}, acc = {acc_count/validate_size}')\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting: layer=2, neuron=[32, 4]\n",
      "best result at epoch 130: train_loss = 0.06198728100357578, validate_loss = 0.06236801608016579, acc = 0.9571875\n"
     ]
    }
   ],
   "source": [
    "print(f'setting: layer={len(layer_neuron)}, neuron={layer_neuron}')\n",
    "print(f'best result at epoch {best_epoch + 1}: train_loss = {best_train_loss}, validate_loss = {best_validate_loss}, acc = {max_acc/validate_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_test_origin = pd.read_csv('data/lab3_test.csv')\n",
    "pd_test_origin = pd_test_origin / 255\n",
    "pd_test_origin = np.array(pd_test_origin)\n",
    "pd_test_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = []\n",
    "for i, feature_data in enumerate(pd_test_origin):\n",
    "    a = {} # output of layers\n",
    "    error = {} # error of layers\n",
    "    a[0] = feature_data\n",
    "\n",
    "    # Forward\n",
    "    for layer, neuron in enumerate(layer_neuron):\n",
    "        output = model.forward(a[layer], best_w[layer+1], best_b[layer+1])            \n",
    "        a[layer+1] = np.array(output.reshape(1,-1))[0]\n",
    "\n",
    "    arr = a[len(layer_neuron)]\n",
    "\n",
    "    for i, data in enumerate(arr):\n",
    "        if data == np.max(arr):\n",
    "            if i == 0:\n",
    "                ans.append(0)\n",
    "            elif i == 1:\n",
    "                ans.append(3)\n",
    "            elif i == 2:\n",
    "                ans.append(8)\n",
    "            elif i == 3:\n",
    "                ans.append(9)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " ...]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ans = pd.DataFrame(ans)\n",
    "test_ans = test_ans.rename({0:'ans'},axis=1)\n",
    "test_ans.to_csv('test_ans.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1bd4997df8f250b7ce125c4f296e41cc30fc4467602168a8546b0db04b01c027"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
